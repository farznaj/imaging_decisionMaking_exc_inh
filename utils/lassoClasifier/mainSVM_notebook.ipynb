{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outcome2ana = 'corr' # correct or incorrect trials\n",
    "\n",
    "mousename = 'fni17'\n",
    "imagingFolder = '151102'\n",
    "mdfFileNumber = [1,2] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/farznaj/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:10: DeprecationWarning: The compiler package is deprecated and removed in Python 3.x.\n"
     ]
    }
   ],
   "source": [
    "# Import Libraries and Modules\n",
    "\n",
    "import scipy.io as scio\n",
    "import scipy as sci\n",
    "import numpy as np\n",
    "import numpy.random as rng\n",
    "\n",
    "from crossValidateModel import crossValidateModel\n",
    "from linearSVM import linearSVM\n",
    "from compiler.ast import flatten\n",
    "import matplotlib \n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline  \n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "matplotlib.rcParams['figure.figsize'] = (8,5)\n",
    "from IPython.display import display\n",
    "import sklearn.svm as svm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '/home/farznaj/anaconda2/lib/python27.zip', '/home/farznaj/anaconda2/lib/python2.7', '/home/farznaj/anaconda2/lib/python2.7/plat-linux2', '/home/farznaj/anaconda2/lib/python2.7/lib-tk', '/home/farznaj/anaconda2/lib/python2.7/lib-old', '/home/farznaj/anaconda2/lib/python2.7/lib-dynload', '/home/farznaj/anaconda2/lib/python2.7/site-packages', '/home/farznaj/anaconda2/lib/python2.7/site-packages/Sphinx-1.4.1-py2.7.egg', '/home/farznaj/anaconda2/lib/python2.7/site-packages/setuptools-23.0.0-py2.7.egg', '/home/farznaj/anaconda2/lib/python2.7/site-packages/IPython/extensions', '/home/farznaj/.ipython']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print sys.path\n",
    "sys.path.append('/home/farznaj/Documents/trial_history/imaging')\n",
    "# print sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/farznaj/Shares/Churchland/data/fni17/imaging/151102/151102_001-002.mat\n",
      "/home/farznaj/Shares/Churchland/data/fni17/imaging/151102/151102_001-002_ch2-PnevPanResults-160830-200511.mat\n",
      "/home/farznaj/Shares/Churchland/data/fni17/imaging/151102/post_151102_001-002_ch2-PnevPanResults-160830-200511.mat\n"
     ]
    }
   ],
   "source": [
    "# Set mat file names\n",
    "\n",
    "pnev2load = [] # which pnev file to load: indicates index of date-sorted files: use 0 for latest. Set [] to load the latest one.\n",
    "signalCh = [2] # since gcamp is channel 2, should be always 2.\n",
    "\n",
    "from setImagingAnalysisNamesP import *\n",
    "\n",
    "imfilename, pnevFileName = setImagingAnalysisNamesP(mousename, imagingFolder, mdfFileNumber, signalCh=signalCh, pnev2load=pnev2load)\n",
    "\n",
    "postName = os.path.join(os.path.dirname(pnevFileName), 'post_'+os.path.basename(pnevFileName))\n",
    "\n",
    "print(imfilename)\n",
    "print(pnevFileName)\n",
    "print(postName)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load matlab variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(76, 297, 178)\n",
      "(78, 297, 178)\n",
      "(178,)\n",
      "(178,)\n",
      "(20, 1)\n"
     ]
    }
   ],
   "source": [
    "# Load aligned traces, frames, frame of event of interest, and epoch over which we will average the responses to do SVM analysis\n",
    "Data = scio.loadmat(postName, variable_names=['stimAl'],squeeze_me=True,struct_as_record=False)\n",
    "\n",
    "eventI = Data['stimAl'].eventI - 1 # remember difference indexing in matlab and python!\n",
    "traces_al_sm = Data['stimAl'].traces.astype('float') # traces_al_sm\n",
    "time_aligned = Data['stimAl'].time.astype('float')\n",
    "ep = Data['stimAl'].ep - 1 # remember difference indexing in matlab and python!\n",
    "# print(eventI)\n",
    "print(np.shape(traces_al_sm))\n",
    "# print(np.shape(time_aligned))\n",
    "# print(ep)\n",
    "\n",
    "Data = scio.loadmat(postName, variable_names=['firstSideTryAl'],squeeze_me=True,struct_as_record=False)\n",
    "traces_al_ch = Data['firstSideTryAl'].traces.astype('float')\n",
    "time_choiceAligned = Data['firstSideTryAl'].time.astype('float')\n",
    "print(np.shape(traces_al_ch))\n",
    "# print(np.shape(time_choiceAligned))\n",
    "\n",
    "\n",
    "# Load outcomes and allResp_HR_LR\n",
    "Data = scio.loadmat(postName, variable_names=['outcomes', 'allResp_HR_LR'])\n",
    "\n",
    "outcomes = (Data.pop('outcomes').astype('float'))[0,:]\n",
    "allResp_HR_LR = (Data.pop('allResp_HR_LR').astype('float'))[0,:]\n",
    "print(outcomes.shape)\n",
    "print(allResp_HR_LR.shape)\n",
    "\n",
    "\n",
    "# Set to nan those trials in outcomes and allRes that are nan in traces_al_sm\n",
    "I = (np.argwhere((~np.isnan(traces_al_sm).sum(axis=0)).sum(axis=1)))[0][0] # first non-nan neuron\n",
    "allTrs2rmv = np.argwhere(sum(np.isnan(traces_al_sm[:,I,:])))\n",
    "print(np.shape(allTrs2rmv))\n",
    "\n",
    "outcomes[allTrs2rmv] = np.nan\n",
    "allResp_HR_LR[allTrs2rmv] = np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(178,)\n"
     ]
    }
   ],
   "source": [
    "# Set Y: the response vector\n",
    "\n",
    "# if trialHistAnalysis\n",
    "#     popClassifier_trialHistory\n",
    "# else\n",
    "choiceVec0 = np.transpose(allResp_HR_LR);  # trials x 1;  1 for HR choice, 0 for LR choice. % choice of the current trial.\n",
    "\n",
    "if outcome2ana == 'corr':\n",
    "    choiceVec0[outcomes!=1] = np.nan; # analyze only correct trials.\n",
    "elif outcome2ana == 'incorr':\n",
    "    choiceVec0[outcomes!=0] = np.nan; # analyze only incorrect trials.\n",
    "\n",
    "# Y = choiceVec0\n",
    "print(choiceVec0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(178, 297)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/farznaj/anaconda2/lib/python2.7/site-packages/numpy/lib/nanfunctions.py:675: RuntimeWarning: Mean of empty slice\n",
      "  warnings.warn(\"Mean of empty slice\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "# Set X: the predictor matrix (trials x neurons) that shows average of spikes for a particular epoch for each trial and neuron.\n",
    "\n",
    "spikeAveEp0 = np.transpose(np.nanmean(traces_al_sm[ep,:,:], axis=0)) # trials x neurons\n",
    "# spikeAveEp0 = np.matrix(np.transpose(np.nanmean(traces_al_sm[ep,:,:], axis=0))) # trials x neurons\n",
    "\n",
    "# X = spikeAveEp0;\n",
    "print(spikeAveEp0.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The data has 119 trials recorded from 297 neurons\n",
      " The data has 76 frames recorded from 297 neurons at 158 trials\n"
     ]
    }
   ],
   "source": [
    "#     - X matrix (size trials x neurons) that contains neural responses at different trials.\n",
    "#     - Y choice of high rate (modeled as 1) and low rate (modeled as 0)\n",
    "\n",
    "'''\n",
    "#dirName = 'SVM_151102_001-002_ch2-PnevPanResults-160624-113108';\n",
    "dirName = 'SVM_151029_003_ch2-PnevPanResults-160426-191859';\n",
    "#dirName = '/home/farznaj/Shares/Churchland/data/fni17/imaging/151022/XY_fni17_151022 XY_lassoSVM.mat';\n",
    "Data = scio.loadmat(dirName, variable_names=['X', 'Y', 'time_aligned', 'non_filtered', 'traces_al_1stSideTry', 'time_aligned_1stSideTry']);\n",
    "X = Data.pop('X').astype('float')\n",
    "Y = np.squeeze(Data.pop('Y')).astype('int')\n",
    "time_aligned = np.squeeze(Data.pop('time_aligned')).astype('float')\n",
    "Xt = Data.pop('non_filtered').astype('float')\n",
    "Xt_choiceAligned = Data.pop('traces_al_1stSideTry').astype('float')\n",
    "time_choiceAligned = np.squeeze(Data.pop('time_aligned_1stSideTry')).astype('float')\n",
    "'''\n",
    "\n",
    "# mskNan = (np.sum(np.isnan(spikeAveEp0), axis = 1) + np.isnan(choiceVec0))==0\n",
    "mskNan = (np.sum(np.isnan(spikeAveEp0), axis = 1) + np.isnan(choiceVec0)) == 0\n",
    "X = spikeAveEp0[mskNan,:];\n",
    "Y = choiceVec0[mskNan];\n",
    "\n",
    "Xt = traces_al_sm[:, :, np.sum(np.sum(np.isnan(traces_al_sm), axis =0), axis =0)==0];\n",
    "Xt_choiceAligned = traces_al_ch[:, :, np.sum(np.sum(np.isnan(traces_al_ch), axis =0), axis =0)==0];\n",
    "numTrials, numNeurons = X.shape\n",
    "print ' The data has %d trials recorded from %d neurons' %(numTrials, numNeurons)\n",
    "print ' The data has %d frames recorded from %d neurons at %d trials' %Xt.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features normalization and scaling\n",
    "    To removed effects related to scaling and bias of each neuron, we need to zscore data (i.e., make data mean 0 and variance 1 for each neuron) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/farznaj/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:3: RuntimeWarning: invalid value encountered in divide\n",
      "  app.launch_new_instance()\n",
      "/home/farznaj/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:6: RuntimeWarning: divide by zero encountered in divide\n",
      "/home/farznaj/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:6: RuntimeWarning: invalid value encountered in divide\n",
      "/home/farznaj/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:12: RuntimeWarning: divide by zero encountered in divide\n",
      "/home/farznaj/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:12: RuntimeWarning: invalid value encountered in divide\n"
     ]
    }
   ],
   "source": [
    "meanX = np.mean(X, axis = 0);\n",
    "stdX = np.std(X, axis = 0);\n",
    "X = (X-meanX)/stdX;\n",
    "Tc, Nc, Cc = Xt_choiceAligned.shape\n",
    "Xtc_N = np.reshape(Xt_choiceAligned.transpose(0 ,2 ,1), (Tc*Cc, Nc), order = 'F')\n",
    "Xtc_N = (Xtc_N-meanX)/stdX\n",
    "Xtc = np.reshape(Xtc_N, (Tc, Cc, Nc), order = 'F').transpose(0 ,2 ,1)\n",
    "\n",
    "\n",
    "T, N, C = Xt.shape\n",
    "Xt_N = np.reshape(Xt.transpose(0 ,2 ,1), (T*C, N), order = 'F')\n",
    "Xt_N = (Xt_N-meanX)/stdX\n",
    "Xt = np.reshape(Xt_N, (T, C, N), order = 'F').transpose(0 ,2 ,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divide data to high and low rates\n",
    "    Divide data to high rate trials and low rate trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 58 trials are high rate and 61 trials are low rate\n"
     ]
    }
   ],
   "source": [
    "Y_HR = Y[Y==1];\n",
    "X_HR = X[Y==1,:];\n",
    "Y_LR = Y[Y==0];\n",
    "X_LR = X[Y==0,:];\n",
    "print ' %d trials are high rate and %d trials are low rate' %(len(Y_HR), len(Y_LR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle imbalance in the number of trials\n",
    "    - Still need to think about that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify the best regularization parameter:\n",
    "    Perform 10-fold cross validation to obtain the best regularization parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running l1 svm classification\r\n",
      "try the following regularization values: %\n",
      "[  8.40336134e-07   1.33184302e-06   2.11082893e-06   3.34543841e-06\n",
      "   5.30216256e-06   8.40336134e-06   1.33184302e-05   2.11082893e-05\n",
      "   3.34543841e-05   5.30216256e-05   8.40336134e-05   1.33184302e-04\n",
      "   2.11082893e-04   3.34543841e-04   5.30216256e-04   8.40336134e-04\n",
      "   1.33184302e-03   2.11082893e-03   3.34543841e-03   5.30216256e-03\n",
      "   8.40336134e-03   1.33184302e-02   2.11082893e-02   3.34543841e-02\n",
      "   5.30216256e-02   8.40336134e-02   1.33184302e-01   2.11082893e-01\n",
      "   3.34543841e-01   5.30216256e-01   8.40336134e-01   1.33184302e+00\n",
      "   2.11082893e+00   3.34543841e+00   5.30216256e+00   8.40336134e+00\n",
      "   1.33184302e+01   2.11082893e+01   3.34543841e+01   5.30216256e+01\n",
      "   8.40336134e+01   1.33184302e+02   2.11082893e+02   3.34543841e+02\n",
      "   5.30216256e+02   8.40336134e+02   1.33184302e+03   2.11082893e+03\n",
      "   3.34543841e+03   5.30216256e+03]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-3daa43d1b309>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcvect\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mregType\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'l1'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m             \u001b[0msummary\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mcrossValidateModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlinearSVM\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkfold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkfold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcvect\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mregType\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'l2'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m             \u001b[0msummary\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mcrossValidateModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlinearSVM\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkfold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkfold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcvect\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/farznaj/Documents/trial_history/utils/lassoClasifier/crossValidateModel.py\u001b[0m in \u001b[0;36mcrossValidateModel\u001b[1;34m(X, Y, modelFn, **options)\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[0mXTest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mXs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkfold\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1.\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mkfold\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnumObservations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumObservations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m     \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodelFn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXTrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mYTrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXTest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mYTest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/farznaj/Documents/trial_history/utils/lassoClasifier/linearSVM.py\u001b[0m in \u001b[0;36mlinearSVM\u001b[1;34m(XTrain, YTrain, XTest, YTest, options)\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;31m#print 'running l2 svm classification\\r'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mlinear_svm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLinearSVC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mC\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ml2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'squared_hinge'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpenalty\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'l2'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdual\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0mlinear_svm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXTrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mYTrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mperClassError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mYhat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/farznaj/anaconda2/lib/python2.7/site-packages/sklearn/svm/classes.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m         X, y = check_X_y(X, y, accept_sparse='csr',\n\u001b[1;32m--> 205\u001b[1;33m                          dtype=np.float64, order=\"C\")\n\u001b[0m\u001b[0;32m    206\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/farznaj/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    508\u001b[0m     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n\u001b[0;32m    509\u001b[0m                     \u001b[0mensure_2d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_nd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 510\u001b[1;33m                     ensure_min_features, warn_on_dtype, estimator)\n\u001b[0m\u001b[0;32m    511\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    512\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[1;32m/home/farznaj/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    396\u001b[0m                              % (array.ndim, estimator_name))\n\u001b[0;32m    397\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 398\u001b[1;33m             \u001b[0m_assert_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    399\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    400\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/farznaj/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X)\u001b[0m\n\u001b[0;32m     52\u001b[0m             and not np.isfinite(X).all()):\n\u001b[0;32m     53\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[1;32m---> 54\u001b[1;33m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "regType = 'l1'\n",
    "kfold = 10;\n",
    "numSamples = 100;\n",
    "if regType == 'l1':\n",
    "    print 'running l1 svm classification\\r' \n",
    "    cvect = 10**(np.arange(-4, 6,0.2))/numTrials;\n",
    "elif regType == 'l2':\n",
    "    print 'running l2 svm classification\\r' \n",
    "    cvect = 10**(np.arange(-4, 6,0.2));\n",
    "\n",
    "print 'try the following regularization values: %\\n', cvect\n",
    "\n",
    "perClassErrorTrain = np.ones((numSamples, len(cvect)))+np.nan;\n",
    "perClassErrorTest = np.ones((numSamples, len(cvect)))+np.nan;\n",
    "for s in range(numSamples):\n",
    "    for i in range(len(cvect)):\n",
    "        if regType == 'l1':\n",
    "            summary =  crossValidateModel(X, Y, linearSVM, kfold = kfold, l1 = cvect[i])\n",
    "        elif regType == 'l2':\n",
    "            summary =  crossValidateModel(X, Y, linearSVM, kfold = kfold, l2 = cvect[i])\n",
    "\n",
    "        perClassErrorTrain[s, i] = summary.perClassErrorTrain;\n",
    "        perClassErrorTest[s, i] = summary.perClassErrorTest;\n",
    "\n",
    "meanPerClassErrorTrain = np.mean(perClassErrorTrain, axis = 0);\n",
    "semPerClassErrorTrain = np.std(perClassErrorTrain, axis = 0)/np.sqrt(numSamples);\n",
    "\n",
    "meanPerClassErrorTest = np.mean(perClassErrorTest, axis = 0);\n",
    "semPerClassErrorTest = np.std(perClassErrorTest, axis = 0)/np.sqrt(numSamples);\n",
    "ix = np.argmin(meanPerClassErrorTest);\n",
    "cbest = cvect[meanPerClassErrorTest <= (meanPerClassErrorTest[ix]+semPerClassErrorTest[ix])];\n",
    "cbest = cbest[0]; # best regularization term based on minError+SE criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##%%%%%% plot coss-validation results\n",
    "plt.figure('cross validation')\n",
    "\n",
    "plt.fill_between(cvect, meanPerClassErrorTrain-semPerClassErrorTrain, meanPerClassErrorTrain+ semPerClassErrorTrain, alpha=0.5, edgecolor='k', facecolor='k')\n",
    "plt.fill_between(cvect, meanPerClassErrorTest-semPerClassErrorTest, meanPerClassErrorTest+ semPerClassErrorTest, alpha=0.5, edgecolor='r', facecolor='r')\n",
    "plt.plot(cvect, meanPerClassErrorTrain, 'k', label = 'training')\n",
    "plt.plot(cvect, meanPerClassErrorTest, 'r', label = 'validation')\n",
    "plt.plot(cvect[cvect==cbest], meanPerClassErrorTest[cvect==cbest], 'bo')\n",
    "plt.xlim([cvect[1], cvect[-1]])\n",
    "plt.xscale('log')\n",
    "plt.xlabel('regularization parameter')\n",
    "plt.ylabel('classification error (%)')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Train the best SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if regType == 'l1':\n",
    "    linear_svm = svm.LinearSVC(C = cbest, loss='squared_hinge', penalty='l1', dual=False)\n",
    "elif regType == 'l2':\n",
    "    linear_svm = svm.LinearSVC(C = cbest, loss='squared_hinge', penalty='l2', dual=True)\n",
    "\n",
    "linear_svm.fit(X, Y)\n",
    "    \n",
    "w = np.squeeze(linear_svm.coef_);\n",
    "b = linear_svm.intercept_;\n",
    "\n",
    "plt.figure()\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(w[np.argsort(abs(w))[::-1]], 'k.', label = 'weights')\n",
    "plt.plot(np.ones(len(w))*b, 'k--', label = 'bias')\n",
    "plt.xlabel('sorted neurons')\n",
    "plt.legend()\n",
    "plt.title(('Training error: %.2f %%' %(abs(linear_svm.predict(X)-Y.astype('float')).sum()/len(Y)*100)))\n",
    "print abs(((np.dot(X,w)+b)>0).astype('float')-Y.astype('float')).sum()/len(Y)*100 # this is the prediction formula\n",
    "plt.subplot(1,2,2)\n",
    "plt.hist(w, 20,orientation='horizontal', color = 'k')\n",
    "plt.ylabel('weights')\n",
    "plt.xlabel('count')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Null distribution using shuffles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "numShuffles = 100\n",
    "summary_data = [];\n",
    "summary_shfl = [];\n",
    "perClassErrorTrain_data = [];\n",
    "perClassErrorTest_data = []\n",
    "perClassErrorTrain_shfl = [];\n",
    "perClassErrorTest_shfl = [];\n",
    "w_data = []\n",
    "b_data = []\n",
    "w_shfl = []\n",
    "b_shfl = []\n",
    "permIxsList = [];\n",
    "for i in range(numShuffles):\n",
    "    permIxs = rng.permutation(numTrials);\n",
    "    permIxsList.append(permIxs);\n",
    "    if regType == 'l1':\n",
    "        summary_data.append(crossValidateModel(X, Y, linearSVM, kfold = kfold, l1 = cbest))\n",
    "        summary_shfl.append(crossValidateModel(X, Y[permIxs], linearSVM, kfold = kfold, l1 = cbest))\n",
    "    elif regType == 'l2':\n",
    "        summary_data.append(crossValidateModel(X, Y, linearSVM, kfold = kfold, l2 = cbest))\n",
    "        summary_shfl.append(crossValidateModel(X, Y[permIxs], linearSVM, kfold = kfold, l2 = cbest))\n",
    "        \n",
    "    perClassErrorTrain_data.append(summary_data[i].perClassErrorTrain);\n",
    "    perClassErrorTest_data.append(summary_data[i].perClassErrorTest);\n",
    "    w_data.append(np.squeeze(summary_data[i].model.coef_));\n",
    "    b_data.append(summary_data[i].model.intercept_);\n",
    "        \n",
    "    perClassErrorTrain_shfl.append(summary_shfl[i].perClassErrorTrain);\n",
    "    perClassErrorTest_shfl.append(summary_shfl[i].perClassErrorTest);\n",
    "    w_shfl.append(np.squeeze(summary_shfl[i].model.coef_));\n",
    "    b_shfl.append(summary_shfl[i].model.intercept_);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "binEvery = 3; # bin width\n",
    "plt.figure()\n",
    "plt.subplot(1,2,1)\n",
    "plt.hist(perClassErrorTrain_data, np.arange(0,100,binEvery), color = 'k', label = 'data');\n",
    "plt.hist(perClassErrorTrain_shfl, np.arange(0,100,binEvery), color = [0.5, 0.5, 0.5], label = 'shuffled');\n",
    "plt.xlabel('Training classification error (%)')\n",
    "plt.ylabel('count')\n",
    "plt.title('Mean data: %.2f %%, Mean shuffled: %.2f %%,' %(np.mean(perClassErrorTrain_data), np.mean(perClassErrorTrain_shfl)), fontsize = 10)\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.hist(perClassErrorTest_data, np.arange(0,100,binEvery), color = 'k', label = 'data');\n",
    "plt.hist(perClassErrorTest_shfl, np.arange(0,100,binEvery), color = [0.5, 0.5, 0.5], label = 'shuffled');\n",
    "plt.legend()\n",
    "plt.xlabel('Testing classification error (%)')\n",
    "plt.title('Mean data: %.2f %%, Mean shuffled: %.2f %%,' %(np.mean(perClassErrorTest_data), np.mean(perClassErrorTest_shfl)), fontsize = 10)\n",
    "plt.ylabel('count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Data projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w_normalized = w/sci.linalg.norm(w);\n",
    "XtcN_w = np.dot(Xtc_N, w_normalized);\n",
    "Xtc_w = np.reshape(XtcN_w, (Tc,Cc), order='F');\n",
    "\n",
    "XtN_w = np.dot(Xt_N, w_normalized);\n",
    "Xt_w = np.reshape(XtN_w, (T,C), order='F');\n",
    "\n",
    "plt.figure()\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(time_aligned, np.mean(Xt_w[:, Y>0],  axis = 1), 'r', label = 'high rate')\n",
    "plt.plot(time_aligned, np.mean(Xt_w[:, Y<1],  axis = 1), 'b', label = 'low rate')\n",
    "plt.xlabel('time aligned to stimulus onset (ms)')\n",
    "plt.title('Projections onto classifier weights')\n",
    "plt.legend()\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(time_aligned, np.mean(Xt[:, :, Y<1],  axis = (1, 2)), 'r', label = 'high rate')\n",
    "plt.plot(time_aligned, np.mean(Xt[:, :, Y>0],  axis = (1, 2)), 'b', label = 'low rate')\n",
    "plt.xlabel('time aligned to stimulus onset (ms)')\n",
    "plt.title('Population average')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(time_choiceAligned, np.mean(Xtc_w[:, Y>0],  axis = 1), 'r', label = 'high rate')\n",
    "plt.plot(time_choiceAligned, np.mean(Xtc_w[:, Y<1],  axis = 1), 'b', label = 'low rate')\n",
    "plt.xlabel('time aligned to 1st choice (ms)')\n",
    "plt.title('Projections onto classifier weights')\n",
    "plt.legend()\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(time_choiceAligned, np.mean(Xtc[:, :, Y<1],  axis = (1, 2)), 'r', label = 'high rate')\n",
    "plt.plot(time_choiceAligned, np.mean(Xtc[:, :, Y>0],  axis = (1, 2)), 'b', label = 'low rate')\n",
    "plt.xlabel('time aligned to 1st choice (ms)')\n",
    "plt.title('Population average')\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Classification error per time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "perClassEr_t = [];\n",
    "for t in range(T):\n",
    "    perClassEr_t.append(abs(linear_svm.predict(np.squeeze(Xt[t, :, :]).T)-Y).mean()*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(time_aligned, perClassEr_t)\n",
    "plt.xlabel('time aligned to stimulus onset (ms)')\n",
    "plt.ylabel('classification error (%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## save results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scio.savemat('svmResults.mat', {'X': X, 'Y': Y, 'Xt_N': Xt_N, 'Xt': Xt, 'w':w, 'b': b })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
