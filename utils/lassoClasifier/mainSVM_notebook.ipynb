{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries and Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy.io as scio\n",
    "import numpy as np\n",
    "import numpy.random as rng\n",
    "\n",
    "from crossValidateModel import crossValidateModel\n",
    "from linearSVM import linearSVM\n",
    "from compiler.ast import flatten\n",
    "import matplotlib \n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline  \n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "matplotlib.rcParams['figure.figsize'] = (8,5)\n",
    "from IPython.display import display\n",
    "import sklearn.svm as svm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "Load dataset from desk. These are:\n",
    "    - X matrix (size trials x neurons) that contains neural responses at different trials.\n",
    "    - Y choice of high rate (modeled as 1) and low rate (modeled as 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The data has 119 neurons recorded at 568 trials\n"
     ]
    }
   ],
   "source": [
    "dirName = 'SVM_151102_001-002_ch2-PnevPanResults-160624-113108';\n",
    "#dirName = '/home/farznaj/Shares/Churchland/data/fni17/imaging/151022/XY_fni17_151022 XY_lassoSVM.mat';\n",
    "XY = scio.loadmat(dirName, variable_names=['X', 'Y']);\n",
    "X = XY.pop('X').astype('float')\n",
    "Y = np.squeeze(XY.pop('Y')).astype('int')\n",
    "numTrials, numNeurons = X.shape\n",
    "\n",
    "print ' The data has %d neurons recorded at %d trials' %(numTrials, numNeurons)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features normalization and scaling\n",
    "    To removed effects related to scaling and bias of each neuron, we need to zscore data (i.e., make data mean 0 and variance 1 for each neuron) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mskNan = (np.sum(np.isnan(X), axis = 1) + np.isnan(Y))==0\n",
    "X = X[mskNan, :];\n",
    "Y = Y[mskNan];\n",
    "meanX = np.mean(X, axis = 0);\n",
    "stdX = np.std(X, axis = 0);\n",
    "X = (X-meanX)/stdX;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divide data to high and low rates\n",
    "    Divide data to high rate trials and low rate trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 58 trials are high rate and 61 trials are low rate\n"
     ]
    }
   ],
   "source": [
    "Y_HR = Y[Y==1];\n",
    "X_HR = X[Y==1,:];\n",
    "Y_LR = Y[Y==0];\n",
    "X_LR = X[Y==0,:];\n",
    "print ' %d trials are high rate and %d trials are low rate' %(len(Y_HR), len(Y_LR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle inbalance in the number of trials\n",
    "    - Still need to think about that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify the best regularization parameter:\n",
    "    Perform 10-fold cross validation to obtain the best regularization parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running l1 svm classification\r\n",
      "try the following regularization values: %\n",
      "[  8.40336134e-08   2.65737619e-07   8.40336134e-07   2.65737619e-06\n",
      "   8.40336134e-06   2.65737619e-05   8.40336134e-05   2.65737619e-04\n",
      "   8.40336134e-04   2.65737619e-03   8.40336134e-03   2.65737619e-02\n",
      "   8.40336134e-02   2.65737619e-01   8.40336134e-01   2.65737619e+00\n",
      "   8.40336134e+00   2.65737619e+01   8.40336134e+01   2.65737619e+02]\n"
     ]
    }
   ],
   "source": [
    "regType = 'l1'\n",
    "kfold = 10;\n",
    "numSamples = 100;\n",
    "if regType == 'l1':\n",
    "    print 'running l1 svm classification\\r' \n",
    "    cvect = 10**(np.arange(-5, 5,0.5))/numTrials;\n",
    "elif regType == 'l2':\n",
    "    print 'running l2 svm classification\\r' \n",
    "    cvect = 10**(np.arange(-5, 5,0.5));\n",
    "\n",
    "print 'try the following regularization values: %\\n', cvect\n",
    "\n",
    "perClassErrorTrain = np.ones((numSamples, len(cvect)))+np.nan;\n",
    "perClassErrorTest = np.ones((numSamples, len(cvect)))+np.nan;\n",
    "for s in range(numSamples):\n",
    "    for i in range(len(cvect)):\n",
    "        if regType == 'l1':\n",
    "            summary =  crossValidateModel(X, Y, linearSVM, kfold = kfold, l1 = cvect[i])\n",
    "        elif regType == 'l2':\n",
    "            summary =  crossValidateModel(X, Y, linearSVM, kfold = kfold, l2 = cvect[i])\n",
    "\n",
    "        perClassErrorTrain[s, i] = summary.perClassErrorTrain;\n",
    "        perClassErrorTest[s, i] = summary.perClassErrorTest;\n",
    "\n",
    "meanPerClassErrorTrain = np.mean(perClassErrorTrain, axis = 0);\n",
    "semPerClassErrorTrain = np.std(perClassErrorTrain, axis = 0)/np.sqrt(numSamples);\n",
    "\n",
    "meanPerClassErrorTest = np.mean(perClassErrorTest, axis = 0);\n",
    "semPerClassErrorTest = np.std(perClassErrorTest, axis = 0)/np.sqrt(numSamples);\n",
    "ix = np.argmin(meanPerClassErrorTest);\n",
    "cbest = cvect[meanPerClassErrorTest <= (meanPerClassErrorTest[ix]+semPerClassErrorTest[ix])];\n",
    "cbest = cbest[0]; # best regularization term based on minError+SE criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##%%%%%% plot coss-validation results\n",
    "plt.figure('cross validation')\n",
    "\n",
    "plt.fill_between(cvect, meanPerClassErrorTrain-semPerClassErrorTrain, meanPerClassErrorTrain+ semPerClassErrorTrain, alpha=0.5, edgecolor='k', facecolor='k')\n",
    "plt.fill_between(cvect, meanPerClassErrorTest-semPerClassErrorTest, meanPerClassErrorTest+ semPerClassErrorTest, alpha=0.5, edgecolor='r', facecolor='r')\n",
    "plt.plot(cvect, meanPerClassErrorTrain, 'k', label = 'training')\n",
    "plt.plot(cvect, meanPerClassErrorTest, 'r', label = 'validation')\n",
    "plt.plot(cvect[cvect==cbest], meanPerClassErrorTest[cvect==cbest], 'bo')\n",
    "plt.xlim([cvect[1], cvect[-1]])\n",
    "plt.xscale('log')\n",
    "plt.xlabel('regularization parameter')\n",
    "plt.ylabel('classification error (%)')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Train the best SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if regType == 'l1':\n",
    "    linear_svm = svm.LinearSVC(C = cbest, loss='squared_hinge', penalty='l1', dual=False)\n",
    "elif regType == 'l2':\n",
    "    linear_svm = svm.LinearSVC(C = cbest, loss='squared_hinge', penalty='l2', dual=True)\n",
    "\n",
    "linear_svm.fit(X, Y)\n",
    "    \n",
    "w = np.squeeze(linear_svm.coef_);\n",
    "b = linear_svm.intercept_;\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(w[np.argsort(abs(w))[::-1]], 'k.', label = 'weights')\n",
    "plt.plot(np.ones(len(w))*b, 'k--', label = 'bias')\n",
    "plt.xlabel('sorted neurons')\n",
    "plt.legend()\n",
    "plt.title(('Training error: %.2f %%' %(abs(linear_svm.predict(X)-Y.astype('float')).sum()/len(Y)*100)))\n",
    "print abs(((np.dot(X,w)+b)>0).astype('float')-Y.astype('float')).sum()/len(Y)*100 # this is the prediction formula\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Null distribution using shuffles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "numShuffles = 1000\n",
    "summary_data = [];\n",
    "summary_shfl = [];\n",
    "perClassErrorTrain_data = [];\n",
    "perClassErrorTest_data = []\n",
    "perClassErrorTrain_shfl = [];\n",
    "perClassErrorTest_shfl = [];\n",
    "w_data = []\n",
    "b_data = []\n",
    "w_shfl = []\n",
    "b_shfl = []\n",
    "permIxsList = [];\n",
    "for i in range(numShuffles):\n",
    "    permIxs = rng.permutation(numTrials);\n",
    "    permIxsList.append(permIxs);\n",
    "    if regType == 'l1':\n",
    "        summary_data.append(crossValidateModel(X, Y, linearSVM, kfold = kfold, l1 = cbest))\n",
    "        summary_shfl.append(crossValidateModel(X, Y[permIxs], linearSVM, kfold = kfold, l1 = cbest))\n",
    "    elif regType == 'l2':\n",
    "        summary_data.append(crossValidateModel(X, Y, linearSVM, kfold = kfold, l2 = cbest))\n",
    "        summary_shfl.append(crossValidateModel(X, Y[permIxs], linearSVM, kfold = kfold, l2 = cbest))\n",
    "        \n",
    "    perClassErrorTrain_data.append(summary_data[i].perClassErrorTrain);\n",
    "    perClassErrorTest_data.append(summary_data[i].perClassErrorTest);\n",
    "    w_data.append(np.squeeze(summary_data[i].model.coef_));\n",
    "    b_data.append(summary_data[i].model.intercept_);\n",
    "        \n",
    "    perClassErrorTrain_shfl.append(summary_shfl[i].perClassErrorTrain);\n",
    "    perClassErrorTest_shfl.append(summary_shfl[i].perClassErrorTest);\n",
    "    w_shfl.append(np.squeeze(summary_shfl[i].model.coef_));\n",
    "    b_shfl.append(summary_shfl[i].model.intercept_);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "binEvery = 3; # bin width\n",
    "plt.figure()\n",
    "plt.subplot(1,2,1)\n",
    "plt.hist(perClassErrorTrain_data, np.arange(0,100,binEvery), color = 'k', label = 'data');\n",
    "plt.hist(perClassErrorTrain_shfl, np.arange(0,100,binEvery), color = [0.5, 0.5, 0.5], label = 'shuffled');\n",
    "plt.xlabel('Training classification error (%)')\n",
    "plt.ylabel('count')\n",
    "plt.title('Mean data: %.2f %%, Mean shuffled: %.2f %%,' %(np.mean(perClassErrorTrain_data), np.mean(perClassErrorTrain_shfl)), fontsize = 10)\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.hist(perClassErrorTest_data, np.arange(0,100,binEvery), color = 'k', label = 'data');\n",
    "plt.hist(perClassErrorTest_shfl, np.arange(0,100,binEvery), color = [0.5, 0.5, 0.5], label = 'shuffled');\n",
    "plt.legend()\n",
    "plt.xlabel('Testing classification error (%)')\n",
    "plt.title('Mean data: %.2f %%, Mean shuffled: %.2f %%,' %(np.mean(perClassErrorTest_data), np.mean(perClassErrorTest_shfl)), fontsize = 10)\n",
    "plt.ylabel('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(w_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run lasso SVM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
