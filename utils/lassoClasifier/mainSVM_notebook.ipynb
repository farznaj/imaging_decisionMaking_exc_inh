{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "6eee2dc9-1ec9-4705-aa55-ecd06847a05d"
    }
   },
   "source": [
    "## Change variables in this cell \n",
    "    - specify the day you want to analyze.\n",
    "    - specifiy trials to be analyzed: correct, incorrect or all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "9c200b2d-dc68-4b64-8d06-fd4f7b6187b8"
    }
   },
   "outputs": [],
   "source": [
    "outcome2ana = 'corr' # '', corr', 'incorr' : analyze all, correct or incorrect trials\n",
    "\n",
    "mousename = 'fni17'\n",
    "imagingFolder = '151102'\n",
    "mdfFileNumber = [1,2] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "d38a63b9-fec1-4f66-856b-d76627310d4c"
    }
   },
   "source": [
    "## Import Libraries and Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "15730e76-0cf7-445e-9d2d-adb7a6728a60"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/ipykernel/__main__.py:8: DeprecationWarning: The compiler package is deprecated and removed in Python 3.x.\n",
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "import scipy.io as scio\n",
    "import scipy as sci\n",
    "import numpy as np\n",
    "import numpy.random as rng\n",
    "\n",
    "from crossValidateModel import crossValidateModel\n",
    "from linearSVM import linearSVM\n",
    "from compiler.ast import flatten\n",
    "import matplotlib \n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline  \n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "matplotlib.rcParams['figure.figsize'] = (8,5)\n",
    "from IPython.display import display\n",
    "import sklearn.svm as svm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "7ec38520-dec9-4b49-9a15-6bf4499ebf3b"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '/Library/Frameworks/Python.framework/Versions/2.7/lib/python27.zip', '/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7', '/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/plat-darwin', '/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/plat-mac', '/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/plat-mac/lib-scriptpackages', '/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/lib-tk', '/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/lib-old', '/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/lib-dynload', '/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages', '/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/gnureadline-6.3.3-py2.7-macosx-10.9-intel.egg', '/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/nose-1.3.6-py2.7.egg', '/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/requests-2.7.0-py2.7.egg', '/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/Sphinx-1.3.1-py2.7.egg', '/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/numpydoc-0.5-py2.7.egg', '/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/sphinx_rtd_theme-0.1.8-py2.7.egg', '/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/alabaster-0.7.4-py2.7.egg', '/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/Babel-1.3-py2.7.egg', '/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/snowballstemmer-1.2.0-py2.7.egg', '/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/docutils-0.12-py2.7.egg', '/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/MarkupSafe-0.23-py2.7-macosx-10.6-intel.egg', '/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/backports.ssl_match_hostname-3.4.0.2-py2.7.egg', '/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/pycog-0.1-py2.7.egg', '/Library/Python/2.7/site-packages', '/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/IPython/extensions', '/Users/gamalamin/.ipython']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print sys.path\n",
    "sys.path.append('/home/farznaj/Documents/trial_history/imaging') # Gamal's dir needs to be added using if that takes the value of pwd\n",
    "# print sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "65954c29-0a9e-47e0-bdd1-fd582bc68831"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Pnev file was found\n",
      "\n",
      "/Users/gamalamin/git_local_repository/Farzaneh/data/fni17/imaging/151102/151102_001-002.mat\n",
      "\n",
      "post_\n"
     ]
    }
   ],
   "source": [
    "# Set mat file names\n",
    "\n",
    "pnev2load = [] # which pnev file to load: indicates index of date-sorted files: use 0 for latest. Set [] to load the latest one.\n",
    "signalCh = [2] # since gcamp is channel 2, should be always 2.\n",
    "\n",
    "from setImagingAnalysisNamesP import *\n",
    "\n",
    "imfilename, pnevFileName = setImagingAnalysisNamesP(mousename, imagingFolder, mdfFileNumber, signalCh=signalCh, pnev2load=pnev2load)\n",
    "\n",
    "postName = os.path.join(os.path.dirname(pnevFileName), 'post_'+os.path.basename(pnevFileName))\n",
    "\n",
    "print(imfilename)\n",
    "print(pnevFileName)\n",
    "print(postName)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "a7922bdf-0e89-4b88-a366-7990f1749819"
    }
   },
   "source": [
    "## Load matlab variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "dea0f2e6-c718-4e16-9104-a49426d7eecc"
    }
   },
   "outputs": [],
   "source": [
    "frameLength = 1000/30.9; # sec.\n",
    "\n",
    "# Load stimulus-aligned traces, frames, frame of event of interest, and epoch over which we will average the responses to do SVM analysis\n",
    "Data = scio.loadmat(postName, variable_names=['stimAl'],squeeze_me=True,struct_as_record=False)\n",
    "eventI = Data['stimAl'].eventI - 1 # remember difference indexing in matlab and python!\n",
    "traces_al_stim = Data['stimAl'].traces.astype('float') # traces_al_stim\n",
    "time_aligned_stim = Data['stimAl'].time.astype('float')\n",
    "ep = Data['stimAl'].ep - 1 # 600ms:stimEnd\n",
    "print 'training epoch is {}'.format(np.round((ep-eventI)*frameLength))\n",
    "print(np.shape(traces_al_stim))\n",
    "# print(np.shape(time_aligned_stim))\n",
    "# print(ep)\n",
    "\n",
    "\n",
    "# Load 1stSideTry-aligned traces, frames, frame of event of interest\n",
    "# use firstSideTryAl_COM to look at changes-of-mind (mouse made a side lick without committing it)\n",
    "Data = scio.loadmat(postName, variable_names=['firstSideTryAl'],squeeze_me=True,struct_as_record=False)\n",
    "traces_al_1stSide = Data['firstSideTryAl'].traces.astype('float')\n",
    "time_aligned_1stSide = Data['firstSideTryAl'].time.astype('float')\n",
    "print(np.shape(traces_al_1stSide))\n",
    "# print(np.shape(time_aligned_1stSide))\n",
    "\n",
    "\n",
    "# Load goTone-aligned traces, frames, frame of event of interest\n",
    "# use goToneAl_noStimAft to make sure there was no stim after go tone.\n",
    "Data = scio.loadmat(postName, variable_names=['goToneAl'],squeeze_me=True,struct_as_record=False)\n",
    "traces_al_go = Data['goToneAl'].traces.astype('float')\n",
    "time_aligned_go = Data['goToneAl'].time.astype('float')\n",
    "print(np.shape(traces_al_go))\n",
    "\n",
    "\n",
    "# Load reward-aligned traces, frames, frame of event of interest\n",
    "Data = scio.loadmat(postName, variable_names=['rewardAl'],squeeze_me=True,struct_as_record=False)\n",
    "traces_al_rew = Data['rewardAl'].traces.astype('float')\n",
    "time_aligned_rew = Data['rewardAl'].time.astype('float')\n",
    "print(np.shape(traces_al_rew))\n",
    "\n",
    "\n",
    "\n",
    "# Load commitIncorrect-aligned traces, frames, frame of event of interest\n",
    "Data = scio.loadmat(postName, variable_names=['commitIncorrAl'],squeeze_me=True,struct_as_record=False)\n",
    "traces_al_incorrResp = Data['commitIncorrAl'].traces.astype('float')\n",
    "time_aligned_incorrResp = Data['commitIncorrAl'].time.astype('float')\n",
    "print(np.shape(traces_al_incorrResp))\n",
    "\n",
    "\n",
    "\n",
    "# Load outcomes and allResp_HR_LR\n",
    "Data = scio.loadmat(postName, variable_names=['outcomes', 'allResp_HR_LR'])\n",
    "\n",
    "outcomes = (Data.pop('outcomes').astype('float'))[0,:]\n",
    "allResp_HR_LR = (Data.pop('allResp_HR_LR').astype('float'))[0,:]\n",
    "# print(outcomes.shape)\n",
    "# print(allResp_HR_LR.shape)\n",
    "\n",
    "# Set to nan those trials in outcomes and allRes that are nan in traces_al_stim\n",
    "I = (np.argwhere((~np.isnan(traces_al_stim).sum(axis=0)).sum(axis=1)))[0][0] # first non-nan neuron\n",
    "allTrs2rmv = np.argwhere(sum(np.isnan(traces_al_stim[:,I,:])))\n",
    "print(np.shape(allTrs2rmv))\n",
    "\n",
    "outcomes[allTrs2rmv] = np.nan\n",
    "allResp_HR_LR[allTrs2rmv] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "26aea324-4089-47e6-8b09-902c6624dbaa"
    }
   },
   "source": [
    "## Set traces (frames x neurons x trials), X (trials x neurons) and Y (trials x 1)\n",
    "    Traces are aligned on stimulus and choice\n",
    "    X matrix (size trials x neurons) that contains neural responses at different trials.\n",
    "    Y choice of high rate (modeled as 1) and low rate (modeled as 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "2e12cfa5-8ba7-40c6-a9dd-81c4841ee78d"
    }
   },
   "outputs": [],
   "source": [
    "# Set Y: the response vector\n",
    "\n",
    "# if trialHistAnalysis\n",
    "#     popClassifier_trialHistory\n",
    "# else\n",
    "choiceVec0 = np.transpose(allResp_HR_LR);  # trials x 1;  1 for HR choice, 0 for LR choice. % choice of the current trial.\n",
    "\n",
    "if outcome2ana == 'corr':\n",
    "    choiceVec0[outcomes!=1] = np.nan; # analyze only correct trials.\n",
    "elif outcome2ana == 'incorr':\n",
    "    choiceVec0[outcomes!=0] = np.nan; # analyze only incorrect trials.\n",
    "\n",
    "# Y = choiceVec0\n",
    "print(choiceVec0.shape)\n",
    "print '#correct choices= %d; #incorrect choices= %d' %(sum(outcomes==1), sum(outcomes==0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "84a66490-cbf7-413a-8033-8da492d05a11"
    }
   },
   "outputs": [],
   "source": [
    "# Set X: the predictor matrix (trials x neurons) that shows average of spikes for a particular epoch for each trial and neuron.\n",
    "\n",
    "spikeAveEp0 = np.transpose(np.nanmean(traces_al_stim[ep,:,:], axis=0)) # trials x neurons\n",
    "# spikeAveEp0 = np.matrix(np.transpose(np.nanmean(traces_al_stim[ep,:,:], axis=0))) # trials x neurons\n",
    "\n",
    "# X = spikeAveEp0;\n",
    "print(spikeAveEp0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "88f9eee6-cc78-4dcf-9fe2-3d6e803617ff"
    }
   },
   "outputs": [],
   "source": [
    "# Set final traces by excluding nan trials and non-active neurons\n",
    "\n",
    "'''\n",
    "#dirName = 'SVM_151102_001-002_ch2-PnevPanResults-160624-113108';\n",
    "dirName = 'SVM_151029_003_ch2-PnevPanResults-160426-191859';\n",
    "#dirName = '/home/farznaj/Shares/Churchland/data/fni17/imaging/151022/XY_fni17_151022 XY_lassoSVM.mat';\n",
    "Data = scio.loadmat(dirName, variable_names=['X', 'Y', 'time_aligned_stim', 'non_filtered', 'traces_al_1stSideTry', 'time_aligned_stim_1stSideTry']);\n",
    "X = Data.pop('X').astype('float')\n",
    "Y = np.squeeze(Data.pop('Y')).astype('int')\n",
    "time_aligned_stim = np.squeeze(Data.pop('time_aligned_stim')).astype('float')\n",
    "Xt = Data.pop('non_filtered').astype('float')\n",
    "Xt_choiceAl = Data.pop('traces_al_1stSideTry').astype('float')\n",
    "time_aligned_1stSide = np.squeeze(Data.pop('time_aligned_stim_1stSideTry')).astype('float')\n",
    "'''\n",
    "\n",
    "# Exclude nan trials\n",
    "trsExcluded = (np.sum(np.isnan(spikeAveEp0), axis = 1) + np.isnan(choiceVec0)) != 0 # NaN trials # trsExcluded\n",
    "# sum(trsExcluded)\n",
    "X = spikeAveEp0[~trsExcluded,:]; # trials x neurons\n",
    "Y = choiceVec0[~trsExcluded];\n",
    "\n",
    "Xt = traces_al_stim[:, :, ~trsExcluded];\n",
    "Xt_choiceAl = traces_al_1stSide[:, :, ~trsExcluded];\n",
    "Xt_goAl = traces_al_go[:, :, ~trsExcluded];\n",
    "Xt_rewAl = traces_al_rew[:, :, ~trsExcluded];\n",
    "Xt_incorrRespAl = traces_al_incorrResp[:, :, ~trsExcluded];\n",
    "## Xt = traces_al_stim[:, :, np.sum(np.sum(np.isnan(traces_al_stim), axis =0), axis =0)==0];\n",
    "## Xt_choiceAl = traces_al_1stSide[:, :, np.sum(np.sum(np.isnan(traces_al_1stSide), axis =0), axis =0)==0];\n",
    "\n",
    "\n",
    "# Identify neurons that did not fire in any of the trials (during ep) and then exclude them. Otherwise they cause problem for feature normalization.\n",
    "nTrsWithSpike = np.sum(X > 0, axis=0) # shows for each neuron, in how many trials the activity was above 0.\n",
    "NsExcluded = (nTrsWithSpike < 1) # identify neurons that were active in no trials.\n",
    "print '# non-active neurons = %d' %(sum(NsExcluded))\n",
    "\n",
    "# Exclude non-active neurons (ie neurons that don't fire in any of the trials during ep)\n",
    "X = X[:,~NsExcluded]\n",
    "Xt = Xt[:,~NsExcluded,:]\n",
    "Xt_choiceAl = Xt_choiceAl[:,~NsExcluded,:]\n",
    "Xt_goAl = Xt_goAl[:,~NsExcluded,:]\n",
    "Xt_rewAl = Xt_rewAl[:,~NsExcluded,:]\n",
    "Xt_incorrRespAl = Xt_incorrRespAl[:,~NsExcluded,:]\n",
    "\n",
    "\n",
    "numTrials, numNeurons = X.shape\n",
    "\n",
    "print ' The data has %d trials recorded from %d neurons' %(numTrials, numNeurons)\n",
    "print ' The data has %d frames recorded from %d neurons at %d trials' %Xt.shape\n",
    "# print(X.shape)\n",
    "# print(Y.shape)\n",
    "# print(Xt.shape)\n",
    "# print(Xt_choiceAl.shape)\n",
    "print(Xt_goAl.shape)\n",
    "\n",
    "# Compute mean and std of X for feature normalization\n",
    "meanX = np.mean(X, axis = 0);\n",
    "stdX = np.std(X, axis = 0);\n",
    "\n",
    "plt.figure\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(meanX)\n",
    "plt.ylabel('meanX (mean FR across trials)')\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(stdX)\n",
    "plt.ylabel('stdX (sd FR across trials)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "b70a9da7-7785-4c2e-a58a-543a577f3a22"
    }
   },
   "source": [
    "## Feature normalization and scaling\n",
    "    To removed effects related to scaling and bias of each neuron, we need to zscore data (i.e., make data mean 0 and variance 1 for each neuron) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "ee7ba9d0-26cd-480d-ad35-589ebdc00038"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# meanX = np.mean(X, axis = 0);\n",
    "# stdX = np.std(X, axis = 0);\n",
    "\n",
    "# normalize X\n",
    "X = (X-meanX)/stdX;\n",
    "\n",
    "# normalize stim-aligned traces\n",
    "T, N, C = Xt.shape\n",
    "Xt_N = np.reshape(Xt.transpose(0 ,2 ,1), (T*C, N), order = 'F')\n",
    "Xt_N = (Xt_N-meanX)/stdX\n",
    "Xt = np.reshape(Xt_N, (T, C, N), order = 'F').transpose(0 ,2 ,1)\n",
    "\n",
    "# normalize goTome-aligned traces\n",
    "Tg, N, C = Xt_goAl.shape\n",
    "Xtg_N = np.reshape(Xt_goAl.transpose(0 ,2 ,1), (Tg*C, N), order = 'F')\n",
    "Xtg_N = (Xtg_N-meanX)/stdX\n",
    "Xtg = np.reshape(Xtg_N, (Tg, C, N), order = 'F').transpose(0 ,2 ,1)\n",
    "\n",
    "# normalize choice-aligned traces\n",
    "Tc, N, C = Xt_choiceAl.shape\n",
    "Xtc_N = np.reshape(Xt_choiceAl.transpose(0 ,2 ,1), (Tc*C, N), order = 'F')\n",
    "Xtc_N = (Xtc_N-meanX)/stdX\n",
    "Xtc = np.reshape(Xtc_N, (Tc, C, N), order = 'F').transpose(0 ,2 ,1)\n",
    "\n",
    "# normalize reward-aligned traces\n",
    "Tr, N, C = Xt_rewAl.shape\n",
    "Xtr_N = np.reshape(Xt_rewAl.transpose(0 ,2 ,1), (Tr*C, N), order = 'F')\n",
    "Xtr_N = (Xtr_N-meanX)/stdX\n",
    "Xtr = np.reshape(Xtr_N, (Tr, C, N), order = 'F').transpose(0 ,2 ,1)\n",
    "\n",
    "# normalize commitIncorrect-aligned traces\n",
    "Tp, N, C = Xt_incorrRespAl.shape\n",
    "Xtp_N = np.reshape(Xt_incorrRespAl.transpose(0 ,2 ,1), (Tp*C, N), order = 'F')\n",
    "Xtp_N = (Xtp_N-meanX)/stdX\n",
    "Xtp = np.reshape(Xtp_N, (Tp, C, N), order = 'F').transpose(0 ,2 ,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "72fa11c2-b5f4-4211-a383-362910a85baa"
    }
   },
   "source": [
    "## Divide data into high-rate and low-rate trials\n",
    "    high-rate: 1\n",
    "    low-rate: 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "2e599579-5983-462d-a928-955a610b5825"
    }
   },
   "outputs": [],
   "source": [
    "Y_HR = Y[Y==1];\n",
    "X_HR = X[Y==1,:];\n",
    "Y_LR = Y[Y==0];\n",
    "X_LR = X[Y==0,:];\n",
    "print ' %d trials are high rate and %d trials are low rate' %(len(Y_HR), len(Y_LR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "01257b9d-092d-4e8e-a16a-ea9f661a3ebc"
    }
   },
   "source": [
    "## Handle imbalance in the number of trials\n",
    "    - Still need to think about that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "9a553ab9-ddea-4aef-a13c-a882046908e4"
    }
   },
   "source": [
    "## Identify the best regularization parameter\n",
    "    Perform 10-fold cross validation to obtain the best regularization parameter\n",
    "        More specifically: \"crossValidateModel\" divides data into training and test datasets. It calls linearSVM.py, which does linear SVM using XTrain, and returns percent class loss for XTrain and XTest.\n",
    "    This procedure gets repeated for numSamples (100 times) for each value of regulariazation parameter. \n",
    "    An average across all 100 samples is computed to find the minimum test class loss.\n",
    "    Best regularization parameter is defined as the smallest regularization parameter whose test-dataset class loss is within mean+sem of minimum test class loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "0f95662b-968a-4d3c-a81c-d9243ac0b070"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "regType = 'l1'\n",
    "kfold = 10;\n",
    "numSamples = 100;\n",
    "if regType == 'l1':\n",
    "    print 'running l1 svm classification\\r' \n",
    "    cvect = 10**(np.arange(-4, 6,0.2))/numTrials;\n",
    "elif regType == 'l2':\n",
    "    print 'running l2 svm classification\\r' \n",
    "    cvect = 10**(np.arange(-4, 6,0.2));\n",
    "\n",
    "print 'try the following regularization values: \\n', cvect\n",
    "\n",
    "perClassErrorTrain = np.ones((numSamples, len(cvect)))+np.nan;\n",
    "perClassErrorTest = np.ones((numSamples, len(cvect)))+np.nan;\n",
    "for s in range(numSamples):\n",
    "    for i in range(len(cvect)):\n",
    "        if regType == 'l1':\n",
    "            summary =  crossValidateModel(X, Y, linearSVM, kfold = kfold, l1 = cvect[i])\n",
    "        elif regType == 'l2':\n",
    "            summary =  crossValidateModel(X, Y, linearSVM, kfold = kfold, l2 = cvect[i])\n",
    "\n",
    "        perClassErrorTrain[s, i] = summary.perClassErrorTrain;\n",
    "        perClassErrorTest[s, i] = summary.perClassErrorTest;\n",
    "\n",
    "meanPerClassErrorTrain = np.mean(perClassErrorTrain, axis = 0);\n",
    "semPerClassErrorTrain = np.std(perClassErrorTrain, axis = 0)/np.sqrt(numSamples);\n",
    "\n",
    "meanPerClassErrorTest = np.mean(perClassErrorTest, axis = 0);\n",
    "semPerClassErrorTest = np.std(perClassErrorTest, axis = 0)/np.sqrt(numSamples);\n",
    "ix = np.argmin(meanPerClassErrorTest);\n",
    "cbest = cvect[meanPerClassErrorTest <= (meanPerClassErrorTest[ix]+semPerClassErrorTest[ix])];\n",
    "cbest = cbest[0]; # best regularization term based on minError+SE criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "0939f724-98b6-4f51-b951-21f406be6202"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##%%%%%% plot coss-validation results\n",
    "print 'Best regularization parameter = %.2f' %cbest\n",
    "plt.figure('cross validation')\n",
    "\n",
    "plt.fill_between(cvect, meanPerClassErrorTrain-semPerClassErrorTrain, meanPerClassErrorTrain+ semPerClassErrorTrain, alpha=0.5, edgecolor='k', facecolor='k')\n",
    "plt.fill_between(cvect, meanPerClassErrorTest-semPerClassErrorTest, meanPerClassErrorTest+ semPerClassErrorTest, alpha=0.5, edgecolor='r', facecolor='r')\n",
    "plt.plot(cvect, meanPerClassErrorTrain, 'k', label = 'training')\n",
    "plt.plot(cvect, meanPerClassErrorTest, 'r', label = 'validation')\n",
    "plt.plot(cvect[cvect==cbest], meanPerClassErrorTest[cvect==cbest], 'bo')\n",
    "plt.xlim([cvect[1], cvect[-1]])\n",
    "plt.xscale('log')\n",
    "plt.xlabel('inverse of regularization parameter (c)')\n",
    "plt.ylabel('classification error (%)')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "2e20583c-e989-413c-ad4c-9d26659fd76a"
    }
   },
   "source": [
    "## Train SVM model using the best regularization parameter\n",
    "    All data in X are used for training.\n",
    "    linear_svm is the trained SVM model that includes weights (w) and intercept (b)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "03f2365a-c960-4015-86f5-94108bb4c62b"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if regType == 'l1':\n",
    "    linear_svm = svm.LinearSVC(C = cbest, loss='squared_hinge', penalty='l1', dual=False)\n",
    "elif regType == 'l2':\n",
    "    linear_svm = svm.LinearSVC(C = cbest, loss='squared_hinge', penalty='l2', dual=True)\n",
    "\n",
    "linear_svm.fit(X, Y)\n",
    "    \n",
    "w = np.squeeze(linear_svm.coef_);\n",
    "b = linear_svm.intercept_;\n",
    "\n",
    "plt.figure()\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(w[np.argsort(abs(w))[::-1]], 'k.', label = 'weights')\n",
    "plt.plot(np.ones(len(w))*b, 'k--', label = 'bias')\n",
    "plt.xlabel('sorted neurons')\n",
    "plt.legend()\n",
    "plt.title(('Training error: %.2f %%' %(abs(linear_svm.predict(X)-Y.astype('float')).sum()/len(Y)*100)))\n",
    "print abs(((np.dot(X,w)+b)>0).astype('float')-Y.astype('float')).sum()/len(Y)*100 # this is the prediction formula\n",
    "plt.subplot(1,2,2)\n",
    "plt.hist(w, 20,orientation='horizontal', color = 'k')\n",
    "plt.ylabel('weights')\n",
    "plt.xlabel('count')\n",
    "\n",
    "linear_svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "0fdae7f1-1443-4fbd-b22e-74db1a4920b8"
    }
   },
   "source": [
    "## Null distribution using shuffles\n",
    "    Compute distritbutions of class loss for train and test datasets by fitting SVM for 100 times.\n",
    "    Do this for both actual data and shuffled data (ie data in which Y is shuffled but X is not to serve as null distribution.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "824a3cbe-9626-4d39-b8c9-f43a6cce3bbb"
    }
   },
   "outputs": [],
   "source": [
    "numShuffles = 100\n",
    "summary_data = [];\n",
    "summary_shfl = [];\n",
    "perClassErrorTrain_data = [];\n",
    "perClassErrorTest_data = []\n",
    "perClassErrorTrain_shfl = [];\n",
    "perClassErrorTest_shfl = [];\n",
    "w_data = []\n",
    "b_data = []\n",
    "w_shfl = []\n",
    "b_shfl = []\n",
    "permIxsList = [];\n",
    "for i in range(numShuffles):\n",
    "    permIxs = rng.permutation(numTrials);\n",
    "    permIxsList.append(permIxs);\n",
    "    if regType == 'l1':\n",
    "        summary_data.append(crossValidateModel(X, Y, linearSVM, kfold = kfold, l1 = cbest))\n",
    "        summary_shfl.append(crossValidateModel(X, Y[permIxs], linearSVM, kfold = kfold, l1 = cbest))\n",
    "    elif regType == 'l2':\n",
    "        summary_data.append(crossValidateModel(X, Y, linearSVM, kfold = kfold, l2 = cbest))\n",
    "        summary_shfl.append(crossValidateModel(X, Y[permIxs], linearSVM, kfold = kfold, l2 = cbest))\n",
    "        \n",
    "    perClassErrorTrain_data.append(summary_data[i].perClassErrorTrain);\n",
    "    perClassErrorTest_data.append(summary_data[i].perClassErrorTest);\n",
    "    w_data.append(np.squeeze(summary_data[i].model.coef_));\n",
    "    b_data.append(summary_data[i].model.intercept_);\n",
    "        \n",
    "    perClassErrorTrain_shfl.append(summary_shfl[i].perClassErrorTrain);\n",
    "    perClassErrorTest_shfl.append(summary_shfl[i].perClassErrorTest);\n",
    "    w_shfl.append(np.squeeze(summary_shfl[i].model.coef_));\n",
    "    b_shfl.append(summary_shfl[i].model.intercept_);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# extend the built in two tailed ttest function to one-tailed\n",
    "def ttest2(a, b, **tailOption):\n",
    "    import scipy.stats as stats\n",
    "    h, p = stats.ttest_ind(a, b)\n",
    "    d = a.mean()-b.mean()\n",
    "    if tailOption.get('tail'):\n",
    "        tail = tailOption.get('tail').lower()\n",
    "        if tail == 'right':\n",
    "            p = p/2.*(d>=0)+(1-p/2.)*(d<0)\n",
    "        elif tail == 'left':\n",
    "            p = 1-p/2.*(d>=0)+(1-p/2.)*(d<0)\n",
    "    return p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "d0236c49-3b10-4062-9996-42cacbc4ef0d"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'perClassErrorTrain_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-59eeb0b02171>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbinEvery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0;31m# bin width\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpvalueTrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mttest2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperClassErrorTrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperClassErrorTrain_shfl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtail\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'right'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mpvalueTest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mttest2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperClassErrorTest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperClassErrorTest_shfl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtail\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'right'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'perClassErrorTrain_data' is not defined"
     ]
    }
   ],
   "source": [
    "binEvery = 3; # bin width\n",
    "pvalueTrain = ttest2(perClassErrorTrain_data, perClassErrorTrain_shfl, tail = 'right');\n",
    "pvalueTest = ttest2(perClassErrorTest_data, perClassErrorTest_shfl, tail = 'right');\n",
    "\n",
    "plt.figure()\n",
    "plt.subplot(1,2,1)\n",
    "plt.hist(perClassErrorTrain_data, np.arange(0,100,binEvery), color = 'k', label = 'data');\n",
    "plt.hist(perClassErrorTrain_shfl, np.arange(0,100,binEvery), color = [0.5, 0.5, 0.5], label = 'shuffled');\n",
    "plt.xlabel('Training classification error (%)')\n",
    "plt.ylabel('count')\n",
    "plt.title('Mean data: %.2f %%, Mean shuffled: %.2f %%, p-value = %.2f' %(np.mean(perClassErrorTrain_data), np.mean(perClassErrorTrain_shfl), pvalueTrain), fontsize = 10)\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.hist(perClassErrorTest_data, np.arange(0,100,binEvery), color = 'k', label = 'data');\n",
    "plt.hist(perClassErrorTest_shfl, np.arange(0,100,binEvery), color = [0.5, 0.5, 0.5], label = 'shuffled');\n",
    "plt.legend()\n",
    "plt.xlabel('Testing classification error (%)')\n",
    "plt.title('Mean data: %.2f %%, Mean shuffled: %.2f %%, p-value = %.2f' %(np.mean(perClassErrorTest_data), np.mean(perClassErrorTest_shfl), pvalueTest), fontsize = 10)\n",
    "plt.ylabel('count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "f3e82548-ca9a-4da9-8a9a-6d748191fddd"
    }
   },
   "source": [
    "## Project traces onto SVM weights\n",
    "    Stimulus-aligned and choice-aligned traces projected onto SVM fitted weights.\n",
    "    More specifically, project traces of all trials onto normalized w (ie SVM weights computed from fitting model using X and Y of all trials)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w_normalized = w/sci.linalg.norm(w);\n",
    "\n",
    "# stim-aligned traces\n",
    "XtN_w = np.dot(Xt_N, w_normalized);\n",
    "Xt_w = np.reshape(XtN_w, (T,C), order='F');\n",
    "\n",
    "# goTone-aligned \n",
    "XtgN_w = np.dot(Xtg_N, w_normalized);\n",
    "Xtg_w = np.reshape(XtgN_w, (Tg,C), order='F');\n",
    "\n",
    "# choice-aligned \n",
    "XtcN_w = np.dot(Xtc_N, w_normalized);\n",
    "Xtc_w = np.reshape(XtcN_w, (Tc,C), order='F');\n",
    "\n",
    "# reward-aligned \n",
    "XtrN_w = np.dot(Xtr_N, w_normalized);\n",
    "Xtr_w = np.reshape(XtrN_w, (Tr,C), order='F');\n",
    "\n",
    "# incommitResp-aligned \n",
    "XtpN_w = np.dot(Xtp_N, w_normalized);\n",
    "Xtp_w = np.reshape(XtpN_w, (Tp,C), order='F');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot projections and raw averages of neural population responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "7d6ee65e-2628-49b7-a725-a506424b141d"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# window of training (ep)\n",
    "win = (ep-eventI)*frameLength\n",
    "\n",
    "\n",
    "# stim-aligned projections and raw average\n",
    "plt.figure()\n",
    "plt.subplot(1,2,1)\n",
    "tr1 = np.mean(Xt_w[:, Y>0],  axis = 1)\n",
    "tr1_se = np.std(Xt_w[:, Y>0],  axis = 1) / np.sqrt(numTrials);\n",
    "tr0 = np.mean(Xt_w[:, Y<1],  axis = 1)\n",
    "tr0_se = np.std(Xt_w[:, Y<1],  axis = 1) / np.sqrt(numTrials);\n",
    "plt.fill_between(time_aligned_stim, tr1-tr1_se, tr1+tr1_se, alpha=0.5, edgecolor='b', facecolor='b')\n",
    "plt.fill_between(time_aligned_stim, tr0-tr0_se, tr0+tr0_se, alpha=0.5, edgecolor='r', facecolor='r')\n",
    "plt.plot(time_aligned_stim, tr1, 'b', label = 'high rate')\n",
    "plt.plot(time_aligned_stim, tr0, 'r', label = 'low rate')\n",
    "mn = np.concatenate([tr1,tr0]).min()\n",
    "mx = np.concatenate([tr1,tr0]).max()\n",
    "plt.plot([win[0], win[0]], [mn, mx], 'g-.') # mark the begining and end of training window\n",
    "plt.plot([win[-1], win[-1]], [mn, mx], 'g-.')\n",
    "plt.xlabel('time aligned to stimulus onset (ms)')\n",
    "plt.title('Projections onto classifier weights')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "a1 = np.mean(Xt[:, :, Y>0],  axis=1) # frames x trials (average across neurons)\n",
    "tr1 = np.mean(a1,  axis = 1)\n",
    "tr1_se = np.std(a1,  axis = 1) / np.sqrt(numTrials);\n",
    "a0 = np.mean(Xt[:, :, Y<1],  axis=1) # frames x trials (average across neurons)\n",
    "tr0 = np.mean(a0,  axis = 1)\n",
    "tr0_se = np.std(a0,  axis = 1) / np.sqrt(numTrials);\n",
    "plt.fill_between(time_aligned_stim, tr1-tr1_se, tr1+tr1_se, alpha=0.5, edgecolor='b', facecolor='b')\n",
    "plt.fill_between(time_aligned_stim, tr0-tr0_se, tr0+tr0_se, alpha=0.5, edgecolor='r', facecolor='r')\n",
    "plt.plot(time_aligned_stim, tr1, 'b', label = 'high rate')\n",
    "plt.plot(time_aligned_stim, tr0, 'r', label = 'low rate')\n",
    "# plt.plot(time_aligned_stim, np.mean(Xt[:, :, Y<1],  axis = (1, 2)), 'r', label = 'high rate')\n",
    "# plt.plot(time_aligned_stim, np.mean(Xt[:, :, Y>0],  axis = (1, 2)), 'b', label = 'low rate')\n",
    "plt.xlabel('time aligned to stimulus onset (ms)')\n",
    "plt.title('Population average')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "\n",
    "# goTone-aligned projections and raw average\n",
    "plt.figure()\n",
    "plt.subplot(1,2,1)\n",
    "tr1 = np.mean(Xtg_w[:, Y>0],  axis = 1)\n",
    "tr1_se = np.std(Xtg_w[:, Y>0],  axis = 1) / np.sqrt(numTrials);\n",
    "tr0 = np.mean(Xtg_w[:, Y<1],  axis = 1)\n",
    "tr0_se = np.std(Xtg_w[:, Y<1],  axis = 1) / np.sqrt(numTrials);\n",
    "plt.fill_between(time_aligned_go, tr1-tr1_se, tr1+tr1_se, alpha=0.5, edgecolor='b', facecolor='b')\n",
    "plt.fill_between(time_aligned_go, tr0-tr0_se, tr0+tr0_se, alpha=0.5, edgecolor='r', facecolor='r')\n",
    "plt.plot(time_aligned_go, tr1, 'b', label = 'high rate')\n",
    "plt.plot(time_aligned_go, tr0, 'r', label = 'low rate')\n",
    "# tr1=np.mean(Xtc_w[:, Y>0],  axis = 1)\n",
    "# tr0=np.mean(Xtc_w[:, Y<1],  axis = 1)\n",
    "# plt.plot(time_aligned_1stSide, tr1, 'r', label = 'high rate')\n",
    "# plt.plot(time_aligned_1stSide, tr0, 'b', label = 'low rate')\n",
    "plt.xlabel('time aligned to go tone (ms)')\n",
    "plt.title('Projections onto classifier weights')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "a1 = np.mean(Xtg[:, :, Y>0],  axis=1) # frames x trials\n",
    "tr1 = np.mean(a1,  axis = 1)\n",
    "tr1_se = np.std(a1,  axis = 1) / np.sqrt(numTrials);\n",
    "a0 = np.mean(Xtg[:, :, Y<1],  axis=1) # frames x trials\n",
    "tr0 = np.mean(a0,  axis = 1)\n",
    "tr0_se = np.std(a0,  axis = 1) / np.sqrt(numTrials);\n",
    "plt.fill_between(time_aligned_go, tr1-tr1_se, tr1+tr1_se, alpha=0.5, edgecolor='b', facecolor='b')\n",
    "plt.fill_between(time_aligned_go, tr0-tr0_se, tr0+tr0_se, alpha=0.5, edgecolor='r', facecolor='r')\n",
    "plt.plot(time_aligned_go, tr1, 'b', label = 'high rate')\n",
    "plt.plot(time_aligned_go, tr0, 'r', label = 'low rate')\n",
    "plt.xlabel('time aligned to go tone (ms)')\n",
    "plt.title('Population average')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "\n",
    "# choice-aligned projections and raw average\n",
    "plt.figure()\n",
    "plt.subplot(1,2,1)\n",
    "tr1 = np.mean(Xtc_w[:, Y>0],  axis = 1)\n",
    "tr1_se = np.std(Xtc_w[:, Y>0],  axis = 1) / np.sqrt(numTrials);\n",
    "tr0 = np.mean(Xtc_w[:, Y<1],  axis = 1)\n",
    "tr0_se = np.std(Xtc_w[:, Y<1],  axis = 1) / np.sqrt(numTrials);\n",
    "plt.fill_between(time_aligned_1stSide, tr1-tr1_se, tr1+tr1_se, alpha=0.5, edgecolor='b', facecolor='b')\n",
    "plt.fill_between(time_aligned_1stSide, tr0-tr0_se, tr0+tr0_se, alpha=0.5, edgecolor='r', facecolor='r')\n",
    "plt.plot(time_aligned_1stSide, tr1, 'b', label = 'high rate')\n",
    "plt.plot(time_aligned_1stSide, tr0, 'r', label = 'low rate')\n",
    "plt.xlabel('time aligned to 1st choice (ms)')\n",
    "plt.title('Projections onto classifier weights')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "a1 = np.mean(Xtc[:, :, Y>0],  axis=1) # frames x trials\n",
    "tr1 = np.mean(a1,  axis = 1)\n",
    "tr1_se = np.std(a1,  axis = 1) / np.sqrt(numTrials);\n",
    "a0 = np.mean(Xtc[:, :, Y<1],  axis=1) # frames x trials\n",
    "tr0 = np.mean(a0,  axis = 1)\n",
    "tr0_se = np.std(a0,  axis = 1) / np.sqrt(numTrials);\n",
    "plt.fill_between(time_aligned_1stSide, tr1-tr1_se, tr1+tr1_se, alpha=0.5, edgecolor='b', facecolor='b')\n",
    "plt.fill_between(time_aligned_1stSide, tr0-tr0_se, tr0+tr0_se, alpha=0.5, edgecolor='r', facecolor='r')\n",
    "plt.plot(time_aligned_1stSide, tr1, 'b', label = 'high rate')\n",
    "plt.plot(time_aligned_1stSide, tr0, 'r', label = 'low rate')\n",
    "plt.xlabel('time aligned to 1st choice (ms)')\n",
    "plt.title('Population average')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# reward-aligned projections and raw average\n",
    "plt.figure()\n",
    "plt.subplot(1,2,1)\n",
    "tr1 = np.mean(Xtr_w[:, Y>0],  axis = 1)\n",
    "tr1_se = np.std(Xtr_w[:, Y>0],  axis = 1) / np.sqrt(numTrials);\n",
    "tr0 = np.mean(Xtr_w[:, Y<1],  axis = 1)\n",
    "tr0_se = np.std(Xtr_w[:, Y<1],  axis = 1) / np.sqrt(numTrials);\n",
    "plt.fill_between(time_aligned_rew, tr1-tr1_se, tr1+tr1_se, alpha=0.5, edgecolor='b', facecolor='b')\n",
    "plt.fill_between(time_aligned_rew, tr0-tr0_se, tr0+tr0_se, alpha=0.5, edgecolor='r', facecolor='r')\n",
    "plt.plot(time_aligned_rew, tr1, 'b', label = 'high rate')\n",
    "plt.plot(time_aligned_rew, tr0, 'r', label = 'low rate')\n",
    "plt.xlabel('time aligned to reward (ms)')\n",
    "plt.title('Projections onto classifier weights')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "a1 = np.mean(Xtr[:, :, Y>0],  axis=1) # frames x trials\n",
    "tr1 = np.mean(a1,  axis = 1)\n",
    "tr1_se = np.std(a1,  axis = 1) / np.sqrt(numTrials);\n",
    "a0 = np.mean(Xtr[:, :, Y<1],  axis=1) # frames x trials\n",
    "tr0 = np.mean(a0,  axis = 1)\n",
    "tr0_se = np.std(a0,  axis = 1) / np.sqrt(numTrials);\n",
    "plt.fill_between(time_aligned_rew, tr1-tr1_se, tr1+tr1_se, alpha=0.5, edgecolor='b', facecolor='b')\n",
    "plt.fill_between(time_aligned_rew, tr0-tr0_se, tr0+tr0_se, alpha=0.5, edgecolor='r', facecolor='r')\n",
    "plt.plot(time_aligned_rew, tr1, 'b', label = 'high rate')\n",
    "plt.plot(time_aligned_rew, tr0, 'r', label = 'low rate')\n",
    "plt.xlabel('time aligned to reward (ms)')\n",
    "plt.title('Population average')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# incommitResp-aligned projections and raw average\n",
    "plt.figure()\n",
    "plt.subplot(1,2,1)\n",
    "tr1 = np.mean(Xtp_w[:, Y>0],  axis = 1)\n",
    "tr1_se = np.std(Xtp_w[:, Y>0],  axis = 1) / np.sqrt(numTrials);\n",
    "tr0 = np.mean(Xtp_w[:, Y<1],  axis = 1)\n",
    "tr0_se = np.std(Xtp_w[:, Y<1],  axis = 1) / np.sqrt(numTrials);\n",
    "plt.fill_between(time_aligned_incorrResp, tr1-tr1_se, tr1+tr1_se, alpha=0.5, edgecolor='b', facecolor='b')\n",
    "plt.fill_between(time_aligned_incorrResp, tr0-tr0_se, tr0+tr0_se, alpha=0.5, edgecolor='r', facecolor='r')\n",
    "plt.plot(time_aligned_incorrResp, tr1, 'b', label = 'high rate')\n",
    "plt.plot(time_aligned_incorrResp, tr0, 'r', label = 'low rate')\n",
    "plt.xlabel('time aligned to incorrResp (ms)')\n",
    "plt.title('Projections onto classifier weights')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "a1 = np.mean(Xtp[:, :, Y>0],  axis=1) # frames x trials\n",
    "tr1 = np.mean(a1,  axis = 1)\n",
    "tr1_se = np.std(a1,  axis = 1) / np.sqrt(numTrials);\n",
    "a0 = np.mean(Xtp[:, :, Y<1],  axis=1) # frames x trials\n",
    "tr0 = np.mean(a0,  axis = 1)\n",
    "tr0_se = np.std(a0,  axis = 1) / np.sqrt(numTrials);\n",
    "plt.fill_between(time_aligned_incorrResp, tr1-tr1_se, tr1+tr1_se, alpha=0.5, edgecolor='b', facecolor='b')\n",
    "plt.fill_between(time_aligned_incorrResp, tr0-tr0_se, tr0+tr0_se, alpha=0.5, edgecolor='r', facecolor='r')\n",
    "plt.plot(time_aligned_incorrResp, tr1, 'b', label = 'high rate')\n",
    "plt.plot(time_aligned_incorrResp, tr0, 'r', label = 'low rate')\n",
    "plt.xlabel('time aligned to incorrResp (ms)')\n",
    "plt.title('Population average')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "b491379f-ef3f-4a82-924a-905110330175"
    }
   },
   "source": [
    "## Classification accuracy at each time point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "702f2432-bd68-4534-a16f-acae33db3026"
    }
   },
   "outputs": [],
   "source": [
    "# perClassCorr_t = [];\n",
    "corrClass = np.ones((T, numTrials)) + np.nan # frames x trials\n",
    "for t in range(T):\n",
    "    trac = np.squeeze(Xt[t, :, :]).T # trials x neurons  # stimulus-aligned trace at time t\n",
    "    corrFract = 1 - abs(linear_svm.predict(trac)-Y); # trials x 1 # fraction of correct choice classification using stimulus-aligned neural responses at time t and the trained SVM model linear_svm.\n",
    "    corrClass[t,:] = corrFract # frames x trials % fraction correct classification for all trials\n",
    "#     perClassCorr_t.append(corrFract.mean()*100) # average correct classification across trials for time point t. Same as np.mean(corrClass, axis=1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = np.mean(corrClass, axis=1)*100 \n",
    "s = np.std(corrClass, axis=1)*100 /np.sqrt(numTrials);\n",
    "\n",
    "plt.figure()\n",
    "plt.fill_between(time_aligned_stim, a-s, a+s, alpha=0.5, edgecolor='r', facecolor='r')\n",
    "plt.plot(time_aligned_stim, a, 'r')\n",
    "plt.xlabel('time since stimulus onset (ms)')\n",
    "plt.ylabel('classification accuracy (%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "83f30129-3af1-4c69-8229-e0e2afc95666"
    }
   },
   "source": [
    "## Save results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "77f22c8d-89cf-40d7-b62b-9be2b9137cca"
    }
   },
   "outputs": [],
   "source": [
    "svmName = os.path.join(os.path.dirname(pnevFileName), 'svmResults_'+os.path.basename(pnevFileName))\n",
    "print(svmName)\n",
    "\n",
    "scio.savemat(svmName, {'w':w, 'b':b, 'cbest':cbest, 'corrClass':corrClass, 'trsExcluded':trsExcluded, 'NsExcluded':NsExcluded, 'meanX':meanX, 'stdX':stdX, 'perClassErrorTrain_data':perClassErrorTrain_data, 'perClassErrorTrain_shfl':perClassErrorTrain_shfl, 'perClassErrorTest_data':perClassErrorTest_data, 'perClassErrorTest_shfl':perClassErrorTest_shfl})\n",
    "\n",
    "# save normalized traces as well                       \n",
    "# scio.savemat(svmName, {w':w, 'b':b, 'cbest':cbest, 'corrClass':corrClass, 'trsExcluded':trsExcluded, 'NsExcluded':NsExcluded, 'meanX':meanX, 'stdX':stdX, 'X':X, 'Y':Y, 'Xt':Xt, 'Xtg':Xtg, 'Xtc':Xtc, 'Xtr':Xtr, 'Xtp':Xtp})\n",
    "# 'linear_svm':linear_svm, \n",
    "\n",
    "# append : doesn't quite work\n",
    "# if os.path.isfile(svmName): \n",
    "#     with open(svmName,'ab') as f:\n",
    "#         sci.io.savemat(f, {'perClassErrorTrain_data':perClassErrorTrain_data, 'perClassErrorTrain_shfl':perClassErrorTrain_shfl, 'perClassErrorTest_data':perClassErrorTest_data, 'perClassErrorTest_shfl':perClassErrorTest_shfl}) # append\n",
    "# else:\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
