{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outcome2ana = 'corr' # correct or incorrect trials\n",
    "\n",
    "mousename = 'fni17'\n",
    "imagingFolder = '151102'\n",
    "mdfFileNumber = [1,2] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/farznaj/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:10: DeprecationWarning: The compiler package is deprecated and removed in Python 3.x.\n"
     ]
    }
   ],
   "source": [
    "# Import Libraries and Modules\n",
    "\n",
    "import scipy.io as scio\n",
    "import scipy as sci\n",
    "import numpy as np\n",
    "import numpy.random as rng\n",
    "\n",
    "from crossValidateModel import crossValidateModel\n",
    "from linearSVM import linearSVM\n",
    "from compiler.ast import flatten\n",
    "import matplotlib \n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline  \n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "matplotlib.rcParams['figure.figsize'] = (8,5)\n",
    "from IPython.display import display\n",
    "import sklearn.svm as svm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '/home/farznaj/anaconda2/lib/python27.zip', '/home/farznaj/anaconda2/lib/python2.7', '/home/farznaj/anaconda2/lib/python2.7/plat-linux2', '/home/farznaj/anaconda2/lib/python2.7/lib-tk', '/home/farznaj/anaconda2/lib/python2.7/lib-old', '/home/farznaj/anaconda2/lib/python2.7/lib-dynload', '/home/farznaj/anaconda2/lib/python2.7/site-packages', '/home/farznaj/anaconda2/lib/python2.7/site-packages/Sphinx-1.4.1-py2.7.egg', '/home/farznaj/anaconda2/lib/python2.7/site-packages/setuptools-23.0.0-py2.7.egg', '/home/farznaj/anaconda2/lib/python2.7/site-packages/IPython/extensions', '/home/farznaj/.ipython']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print sys.path\n",
    "sys.path.append('/home/farznaj/Documents/trial_history/imaging')\n",
    "# print sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/farznaj/Shares/Churchland/data/fni17/imaging/151102/151102_001-002.mat\n",
      "/home/farznaj/Shares/Churchland/data/fni17/imaging/151102/151102_001-002_ch2-PnevPanResults-160830-200511.mat\n",
      "/home/farznaj/Shares/Churchland/data/fni17/imaging/151102/post_151102_001-002_ch2-PnevPanResults-160830-200511.mat\n"
     ]
    }
   ],
   "source": [
    "# Set mat file names\n",
    "\n",
    "pnev2load = [] # which pnev file to load: indicates index of date-sorted files: use 0 for latest. Set [] to load the latest one.\n",
    "signalCh = [2] # since gcamp is channel 2, should be always 2.\n",
    "\n",
    "from setImagingAnalysisNamesP import *\n",
    "\n",
    "imfilename, pnevFileName = setImagingAnalysisNamesP(mousename, imagingFolder, mdfFileNumber, signalCh=signalCh, pnev2load=pnev2load)\n",
    "\n",
    "postName = os.path.join(os.path.dirname(pnevFileName), 'post_'+os.path.basename(pnevFileName))\n",
    "\n",
    "print(imfilename)\n",
    "print(pnevFileName)\n",
    "print(postName)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load matlab variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(76, 297, 178)\n",
      "(78, 297, 178)\n",
      "(1, 178)\n",
      "(20, 1)\n"
     ]
    }
   ],
   "source": [
    "# Load aligned traces, frames, frame of event of interest, and epoch over which we will average the responses to do SVM analysis\n",
    "Data = scio.loadmat(postName, variable_names=['stimAl'],squeeze_me=True,struct_as_record=False)\n",
    "\n",
    "eventI = Data['stimAl'].eventI - 1 # remember difference indexing in matlab and python!\n",
    "traces_al_sm = Data['stimAl'].traces.astype('float') # traces_al_sm\n",
    "time_aligned = Data['stimAl'].time.astype('float')\n",
    "ep = Data['stimAl'].ep - 1 # remember difference indexing in matlab and python!\n",
    "# print(eventI)\n",
    "print(np.shape(traces_al_sm))\n",
    "# print(np.shape(time_aligned))\n",
    "# print(ep)\n",
    "\n",
    "Data = scio.loadmat(postName, variable_names=['firstSideTryAl'],squeeze_me=True,struct_as_record=False)\n",
    "traces_al_ch = Data['firstSideTryAl'].traces.astype('float')\n",
    "time_choiceAligned = Data['firstSideTryAl'].time.astype('float')\n",
    "print(np.shape(traces_al_ch))\n",
    "# print(np.shape(time_choiceAligned))\n",
    "\n",
    "\n",
    "# Load outcomes and allResp_HR_LR\n",
    "Data = scio.loadmat(postName, variable_names=['outcomes', 'allResp_HR_LR'])\n",
    "\n",
    "outcomes = Data.pop('outcomes').astype('float')\n",
    "allResp_HR_LR = Data.pop('allResp_HR_LR').astype('float')\n",
    "print(np.shape(outcomes))\n",
    "\n",
    "\n",
    "# Set to nan those trials in outcomes and allRes that are nan in traces_al_sm\n",
    "I = (np.argwhere((~np.isnan(traces_al_sm).sum(axis=0)).sum(axis=1)))[0][0] # first non-nan neuron\n",
    "allTrs2rmv = np.argwhere(sum(np.isnan(traces_al_sm[:,I,:])))\n",
    "print(np.shape(allTrs2rmv))\n",
    "\n",
    "outcomes[0,allTrs2rmv] = np.nan\n",
    "allResp_HR_LR[0,allTrs2rmv] = np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(178, 1)\n"
     ]
    }
   ],
   "source": [
    "# Set Y: the response vector\n",
    "\n",
    "# if trialHistAnalysis\n",
    "#     popClassifier_trialHistory\n",
    "# else\n",
    "choiceVec0 = np.transpose(allResp_HR_LR);  # trials x 1;  1 for HR choice, 0 for LR choice. % choice of the current trial.\n",
    "np.shape(choiceVec0)\n",
    "\n",
    "if outcome2ana == 'corr':\n",
    "    choiceVec0[np.transpose(outcomes!=1)] = np.nan; # analyze only correct trials.\n",
    "elif outcome2ana == 'incorr':\n",
    "    choiceVec0[np.transpose(outcomes!=0)] = np.nan; # analyze only incorrect trials.\n",
    "\n",
    "# Y = choiceVec0\n",
    "print(choiceVec0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(178, 297)\n"
     ]
    }
   ],
   "source": [
    "# Set X: the predictor matrix (trials x neurons) that shows average of spikes for a particular epoch for each trial and neuron.\n",
    "\n",
    "spikeAveEp0 = np.transpose(np.nanmean(traces_al_sm[ep,:,:], axis=0)) # trials x neurons\n",
    "# spikeAveEp0 = np.matrix(np.transpose(np.nanmean(traces_al_sm[ep,:,:], axis=0))) # trials x neurons\n",
    "\n",
    "# X = spikeAveEp0;\n",
    "print(spikeAveEp0.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The data has 119 trials recorded from 297 neurons\n",
      " The data has 76 frames recorded from 297 neurons at 158 trials\n"
     ]
    }
   ],
   "source": [
    "#     - X matrix (size trials x neurons) that contains neural responses at different trials.\n",
    "#     - Y choice of high rate (modeled as 1) and low rate (modeled as 0)\n",
    "\n",
    "'''\n",
    "#dirName = 'SVM_151102_001-002_ch2-PnevPanResults-160624-113108';\n",
    "dirName = 'SVM_151029_003_ch2-PnevPanResults-160426-191859';\n",
    "#dirName = '/home/farznaj/Shares/Churchland/data/fni17/imaging/151022/XY_fni17_151022 XY_lassoSVM.mat';\n",
    "Data = scio.loadmat(dirName, variable_names=['X', 'Y', 'time_aligned', 'non_filtered', 'traces_al_1stSideTry', 'time_aligned_1stSideTry']);\n",
    "X = Data.pop('X').astype('float')\n",
    "Y = np.squeeze(Data.pop('Y')).astype('int')\n",
    "time_aligned = np.squeeze(Data.pop('time_aligned')).astype('float')\n",
    "Xt = Data.pop('non_filtered').astype('float')\n",
    "Xt_choiceAligned = Data.pop('traces_al_1stSideTry').astype('float')\n",
    "time_choiceAligned = np.squeeze(Data.pop('time_aligned_1stSideTry')).astype('float')\n",
    "'''\n",
    "\n",
    "# mskNan = (np.sum(np.isnan(spikeAveEp0), axis = 1) + np.isnan(choiceVec0))==0\n",
    "mskNan = (np.sum(np.isnan(spikeAveEp0), axis = 1) + np.isnan(choiceVec0.reshape((-1,)))) == 0\n",
    "X = spikeAveEp0[mskNan,:];\n",
    "Y = choiceVec0[mskNan];\n",
    "\n",
    "Xt = traces_al_sm[:, :, np.sum(np.sum(np.isnan(traces_al_sm), axis =0), axis =0)==0];\n",
    "Xt_choiceAligned = traces_al_ch[:, :, np.sum(np.sum(np.isnan(traces_al_ch), axis =0), axis =0)==0];\n",
    "numTrials, numNeurons = X.shape\n",
    "print ' The data has %d trials recorded from %d neurons' %(numTrials, numNeurons)\n",
    "print ' The data has %d frames recorded from %d neurons at %d trials' %Xt.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features normalization and scaling\n",
    "    To removed effects related to scaling and bias of each neuron, we need to zscore data (i.e., make data mean 0 and variance 1 for each neuron) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "meanX = np.mean(X, axis = 0);\n",
    "stdX = np.std(X, axis = 0);\n",
    "X = (X-meanX)/stdX;\n",
    "Tc, Nc, Cc = Xt_choiceAligned.shape\n",
    "Xtc_N = np.reshape(Xt_choiceAligned.transpose(0 ,2 ,1), (Tc*Cc, Nc), order = 'F')\n",
    "Xtc_N = (Xtc_N-meanX)/stdX\n",
    "Xtc = np.reshape(Xtc_N, (Tc, Cc, Nc), order = 'F').transpose(0 ,2 ,1)\n",
    "\n",
    "\n",
    "T, N, C = Xt.shape\n",
    "Xt_N = np.reshape(Xt.transpose(0 ,2 ,1), (T*C, N), order = 'F')\n",
    "Xt_N = (Xt_N-meanX)/stdX\n",
    "Xt = np.reshape(Xt_N, (T, C, N), order = 'F').transpose(0 ,2 ,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divide data to high and low rates\n",
    "    Divide data to high rate trials and low rate trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y_HR = Y[Y==1];\n",
    "X_HR = X[Y==1,:];\n",
    "Y_LR = Y[Y==0];\n",
    "X_LR = X[Y==0,:];\n",
    "print ' %d trials are high rate and %d trials are low rate' %(len(Y_HR), len(Y_LR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle imbalance in the number of trials\n",
    "    - Still need to think about that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify the best regularization parameter:\n",
    "    Perform 10-fold cross validation to obtain the best regularization parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "regType = 'l1'\n",
    "kfold = 10;\n",
    "numSamples = 100;\n",
    "if regType == 'l1':\n",
    "    print 'running l1 svm classification\\r' \n",
    "    cvect = 10**(np.arange(-4, 6,0.2))/numTrials;\n",
    "elif regType == 'l2':\n",
    "    print 'running l2 svm classification\\r' \n",
    "    cvect = 10**(np.arange(-4, 6,0.2));\n",
    "\n",
    "print 'try the following regularization values: %\\n', cvect\n",
    "\n",
    "perClassErrorTrain = np.ones((numSamples, len(cvect)))+np.nan;\n",
    "perClassErrorTest = np.ones((numSamples, len(cvect)))+np.nan;\n",
    "for s in range(numSamples):\n",
    "    for i in range(len(cvect)):\n",
    "        if regType == 'l1':\n",
    "            summary =  crossValidateModel(X, Y, linearSVM, kfold = kfold, l1 = cvect[i])\n",
    "        elif regType == 'l2':\n",
    "            summary =  crossValidateModel(X, Y, linearSVM, kfold = kfold, l2 = cvect[i])\n",
    "\n",
    "        perClassErrorTrain[s, i] = summary.perClassErrorTrain;\n",
    "        perClassErrorTest[s, i] = summary.perClassErrorTest;\n",
    "\n",
    "meanPerClassErrorTrain = np.mean(perClassErrorTrain, axis = 0);\n",
    "semPerClassErrorTrain = np.std(perClassErrorTrain, axis = 0)/np.sqrt(numSamples);\n",
    "\n",
    "meanPerClassErrorTest = np.mean(perClassErrorTest, axis = 0);\n",
    "semPerClassErrorTest = np.std(perClassErrorTest, axis = 0)/np.sqrt(numSamples);\n",
    "ix = np.argmin(meanPerClassErrorTest);\n",
    "cbest = cvect[meanPerClassErrorTest <= (meanPerClassErrorTest[ix]+semPerClassErrorTest[ix])];\n",
    "cbest = cbest[0]; # best regularization term based on minError+SE criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##%%%%%% plot coss-validation results\n",
    "plt.figure('cross validation')\n",
    "\n",
    "plt.fill_between(cvect, meanPerClassErrorTrain-semPerClassErrorTrain, meanPerClassErrorTrain+ semPerClassErrorTrain, alpha=0.5, edgecolor='k', facecolor='k')\n",
    "plt.fill_between(cvect, meanPerClassErrorTest-semPerClassErrorTest, meanPerClassErrorTest+ semPerClassErrorTest, alpha=0.5, edgecolor='r', facecolor='r')\n",
    "plt.plot(cvect, meanPerClassErrorTrain, 'k', label = 'training')\n",
    "plt.plot(cvect, meanPerClassErrorTest, 'r', label = 'validation')\n",
    "plt.plot(cvect[cvect==cbest], meanPerClassErrorTest[cvect==cbest], 'bo')\n",
    "plt.xlim([cvect[1], cvect[-1]])\n",
    "plt.xscale('log')\n",
    "plt.xlabel('regularization parameter')\n",
    "plt.ylabel('classification error (%)')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Train the best SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if regType == 'l1':\n",
    "    linear_svm = svm.LinearSVC(C = cbest, loss='squared_hinge', penalty='l1', dual=False)\n",
    "elif regType == 'l2':\n",
    "    linear_svm = svm.LinearSVC(C = cbest, loss='squared_hinge', penalty='l2', dual=True)\n",
    "\n",
    "linear_svm.fit(X, Y)\n",
    "    \n",
    "w = np.squeeze(linear_svm.coef_);\n",
    "b = linear_svm.intercept_;\n",
    "\n",
    "plt.figure()\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(w[np.argsort(abs(w))[::-1]], 'k.', label = 'weights')\n",
    "plt.plot(np.ones(len(w))*b, 'k--', label = 'bias')\n",
    "plt.xlabel('sorted neurons')\n",
    "plt.legend()\n",
    "plt.title(('Training error: %.2f %%' %(abs(linear_svm.predict(X)-Y.astype('float')).sum()/len(Y)*100)))\n",
    "print abs(((np.dot(X,w)+b)>0).astype('float')-Y.astype('float')).sum()/len(Y)*100 # this is the prediction formula\n",
    "plt.subplot(1,2,2)\n",
    "plt.hist(w, 20,orientation='horizontal', color = 'k')\n",
    "plt.ylabel('weights')\n",
    "plt.xlabel('count')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Null distribution using shuffles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "numShuffles = 100\n",
    "summary_data = [];\n",
    "summary_shfl = [];\n",
    "perClassErrorTrain_data = [];\n",
    "perClassErrorTest_data = []\n",
    "perClassErrorTrain_shfl = [];\n",
    "perClassErrorTest_shfl = [];\n",
    "w_data = []\n",
    "b_data = []\n",
    "w_shfl = []\n",
    "b_shfl = []\n",
    "permIxsList = [];\n",
    "for i in range(numShuffles):\n",
    "    permIxs = rng.permutation(numTrials);\n",
    "    permIxsList.append(permIxs);\n",
    "    if regType == 'l1':\n",
    "        summary_data.append(crossValidateModel(X, Y, linearSVM, kfold = kfold, l1 = cbest))\n",
    "        summary_shfl.append(crossValidateModel(X, Y[permIxs], linearSVM, kfold = kfold, l1 = cbest))\n",
    "    elif regType == 'l2':\n",
    "        summary_data.append(crossValidateModel(X, Y, linearSVM, kfold = kfold, l2 = cbest))\n",
    "        summary_shfl.append(crossValidateModel(X, Y[permIxs], linearSVM, kfold = kfold, l2 = cbest))\n",
    "        \n",
    "    perClassErrorTrain_data.append(summary_data[i].perClassErrorTrain);\n",
    "    perClassErrorTest_data.append(summary_data[i].perClassErrorTest);\n",
    "    w_data.append(np.squeeze(summary_data[i].model.coef_));\n",
    "    b_data.append(summary_data[i].model.intercept_);\n",
    "        \n",
    "    perClassErrorTrain_shfl.append(summary_shfl[i].perClassErrorTrain);\n",
    "    perClassErrorTest_shfl.append(summary_shfl[i].perClassErrorTest);\n",
    "    w_shfl.append(np.squeeze(summary_shfl[i].model.coef_));\n",
    "    b_shfl.append(summary_shfl[i].model.intercept_);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "binEvery = 3; # bin width\n",
    "plt.figure()\n",
    "plt.subplot(1,2,1)\n",
    "plt.hist(perClassErrorTrain_data, np.arange(0,100,binEvery), color = 'k', label = 'data');\n",
    "plt.hist(perClassErrorTrain_shfl, np.arange(0,100,binEvery), color = [0.5, 0.5, 0.5], label = 'shuffled');\n",
    "plt.xlabel('Training classification error (%)')\n",
    "plt.ylabel('count')\n",
    "plt.title('Mean data: %.2f %%, Mean shuffled: %.2f %%,' %(np.mean(perClassErrorTrain_data), np.mean(perClassErrorTrain_shfl)), fontsize = 10)\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.hist(perClassErrorTest_data, np.arange(0,100,binEvery), color = 'k', label = 'data');\n",
    "plt.hist(perClassErrorTest_shfl, np.arange(0,100,binEvery), color = [0.5, 0.5, 0.5], label = 'shuffled');\n",
    "plt.legend()\n",
    "plt.xlabel('Testing classification error (%)')\n",
    "plt.title('Mean data: %.2f %%, Mean shuffled: %.2f %%,' %(np.mean(perClassErrorTest_data), np.mean(perClassErrorTest_shfl)), fontsize = 10)\n",
    "plt.ylabel('count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Data projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w_normalized = w/sci.linalg.norm(w);\n",
    "XtcN_w = np.dot(Xtc_N, w_normalized);\n",
    "Xtc_w = np.reshape(XtcN_w, (Tc,Cc), order='F');\n",
    "\n",
    "XtN_w = np.dot(Xt_N, w_normalized);\n",
    "Xt_w = np.reshape(XtN_w, (T,C), order='F');\n",
    "\n",
    "plt.figure()\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(time_aligned, np.mean(Xt_w[:, Y>0],  axis = 1), 'r', label = 'high rate')\n",
    "plt.plot(time_aligned, np.mean(Xt_w[:, Y<1],  axis = 1), 'b', label = 'low rate')\n",
    "plt.xlabel('time aligned to stimulus onset (ms)')\n",
    "plt.title('Projections onto classifier weights')\n",
    "plt.legend()\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(time_aligned, np.mean(Xt[:, :, Y<1],  axis = (1, 2)), 'r', label = 'high rate')\n",
    "plt.plot(time_aligned, np.mean(Xt[:, :, Y>0],  axis = (1, 2)), 'b', label = 'low rate')\n",
    "plt.xlabel('time aligned to stimulus onset (ms)')\n",
    "plt.title('Population average')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(time_choiceAligned, np.mean(Xtc_w[:, Y>0],  axis = 1), 'r', label = 'high rate')\n",
    "plt.plot(time_choiceAligned, np.mean(Xtc_w[:, Y<1],  axis = 1), 'b', label = 'low rate')\n",
    "plt.xlabel('time aligned to 1st choice (ms)')\n",
    "plt.title('Projections onto classifier weights')\n",
    "plt.legend()\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(time_choiceAligned, np.mean(Xtc[:, :, Y<1],  axis = (1, 2)), 'r', label = 'high rate')\n",
    "plt.plot(time_choiceAligned, np.mean(Xtc[:, :, Y>0],  axis = (1, 2)), 'b', label = 'low rate')\n",
    "plt.xlabel('time aligned to 1st choice (ms)')\n",
    "plt.title('Population average')\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Classification error per time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "perClassEr_t = [];\n",
    "for t in range(T):\n",
    "    perClassEr_t.append(abs(linear_svm.predict(np.squeeze(Xt[t, :, :]).T)-Y).mean()*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(time_aligned, perClassEr_t)\n",
    "plt.xlabel('time aligned to stimulus onset (ms)')\n",
    "plt.ylabel('classification error (%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## save results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scio.savemat('svmResults.mat', {'X': X, 'Y': Y, 'Xt_N': Xt_N, 'Xt': Xt, 'w':w, 'b': b })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
